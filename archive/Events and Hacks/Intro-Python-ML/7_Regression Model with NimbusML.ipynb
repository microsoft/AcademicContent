{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Section 7: Regression Model with NimbusML\n\nWe will create an end-to-end regression model with the wine review dataset. The API of NimbusML is compatible with sklearn, so users who are already familiar with scikit-learn can get started right away. There are also some \"advanced\" techniques which can be helpful for optimal performance:\n\n1. NimbusML pipelines\n2. FileDataStream\n3. Column operations and roles"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "*Let's get started!!*\n\nNote that it would be useful to have this page opened for class referenece:\n\nhttps://docs.microsoft.com/en-us/nimbusml"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1. Quick Start"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The modeling data can be sourced from several different types. Most array-like structures are supported (e.g. lists, numpy arrays, dataframes, series etc.). Let’s look at a simple example."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nimbusml.linear_model import FastLinearClassifier\nX = [[1,2,3],[2,3,4],[-1.2,-1,-7]]\nY = [0,0,1]\n\nmodel = FastLinearClassifier()\nmodel.fit(X,Y)\n\nmodel.predict(X)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can also use Pipeline to include more than one operators in the model, just like sklearn."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nimbusml import Pipeline\nfrom nimbusml.preprocessing.missing_values import Handler as Missingval_Handler\n\nmodel = Pipeline([\n                    Missingval_Handler(), # issues handling integers, input needs to be float\n                    FastLinearClassifier()\n                 ])\nmodel.fit(X,Y)\n\nscores, metrics = model.test(X,Y)\nmetrics",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2. Wine Review Example"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In this section, we are trying to develop a prediction model to use the review data and other information of the wine to predict its price. We will use NimbusML's text featurizer to extract numeric features from the review corpus using **pre-trained** language models.\n\nThe dataset contains a mix of numeric, categorical and text features. This section will demonstrate how  a pipeline of transforms and trainers to do the following.\n\n-\tProcess data directly from files!\n-\tFilter records\n-\tNew : how to apply transforms to just the columns of interest!!\n-\tUsing OneHotVectorizer to encode the categorical features\n-\tUse of NGramFeaturizer  and WordEmbedding transform (a pre-trained DNN model) to convert text to numeric embeddings.\n-\tFeature selection using the CountSelector\n-\tFitting a regression model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2.1 Data Preprocessing - Stream Data from Files"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nimbusml import FileDataStream\n\n# we don't use pandas DataFrame, but FileDataStream to improve performance\nds_train = FileDataStream.read_csv(\"data/wine_train.csv\")\nds_test = FileDataStream.read_csv(\"data/wine_test.csv\")\nds_train.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ds_train.schema",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2.2 Model Development"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the data type, we want to develop a pipeline that applies different operators onto different columns. Note that this pipeline can defintely be improved to achieve better accuracy.  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from IPython.display import Image\nImage(filename='Graphics/1.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nimbusml.preprocessing.missing_values import Filter as Missingval_Filter\nfrom nimbusml.feature_extraction.categorical import OneHotVectorizer\nfrom nimbusml.feature_selection import CountSelector\nfrom nimbusml.feature_extraction.text import NGramFeaturizer\nfrom nimbusml.feature_extraction.text import WordEmbedding\nfrom nimbusml.ensemble import LightGbmRegressor\nfrom nimbusml import Role\n\n# tk = TakeFilter(count = 100) #Always suggested to start with a TakeFilter to quickly examine the pipeline\n\nft = Missingval_Filter()                   << ['price']\n# ft = Missingval_Filter(columns = ['price']) #Equivalent\n\nonv = OneHotVectorizer()                   << ['country', 'province', 'region_1', 'variety']\ncs = CountSelector(count = 2)              << ['country', 'province', 'region_1', 'variety']\n\nng = NGramFeaturizer(output_tokens_column_name = 'description_TransformedText') << ['description']\nwe = WordEmbedding(model_kind = 'SentimentSpecificWordEmbedding')    << ['description_TransformedText']\nlgm = LightGbmRegressor()                  << {'Feature': ['country', 'province', 'region_1', 'variety', \n                                               'description_TransformedText', 'points'],\n                                               'Label': 'price'}\n\n# lgm = LightGbmRegressor(feature = ['country', 'province', 'region_1', 'variety', \n#                                                'description_TransformedText', 'points'],\n#                         label = 'price') #Equivalent\n\nmodel = Pipeline([ft, onv, cs, ng, we, lgm])\nmodel.fit(ds_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Users can specify the input columns for the transform using:\n\n            OneHotVectorizer(columns = ['country', 'province', 'region_1', 'variety'])\nor\n\n            OneHotVectorizer() << ['country', 'province', 'region_1', 'variety']\nBy default, the output column names are the same as the input (overwrite). Users can also specify the new output columns names, therefore, both the input and output columns are preserved.\n\n            OneHotVectorizer(columns = {'country_out': 'country', 'variety_out': 'variety'})\nor\n\n            OneHotVectorizer() << {'country_out': 'country', 'variety_out': 'variety'}\n\nFor learners, users need to specify the roles for the columns by using:\n\n            FastForestRegressor(feature = ['country', 'province'], label = 'price')\n\nThe feature, lable are the \"roles\" users need to specify. Notice that, it is equivalent to use the shift operator:\n\n            FastForestRegressor() << {Role.Feature: ['country', 'province'], Role.Label: 'price'}\n\nWe have well-known names for columns.  For example, column named as “Features” would be treated as a training data.  Column named “Label” will be treated as Label by default . Also, I believe those are case sensitive."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can also plot the pipeline using the plot function."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nimbusml.utils.exports import img_export_pipeline\nfig = img_export_pipeline(model,ds_train) \nfig\n# fig.render(\"Graphics/ppl1.png\") # save this image to files",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2.3 Model Evaluation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "metrics, scores = model.test(ds_test, output_scores=True)\nmetrics",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Image(filename='Graphics/2.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3. Recap\n\nIn this tutorial, we presented an example to:\n\n1. Use NimbusML pipeline\n2. Train the model with FileDataStream\n3. Column operation for transforms and learners:\n\n        For Transforms, always use \"columns = \" (or \"<<\" is equivalent)\n        For learners, specify roles by using \"feature = \", \"label = \" (or \"<< {'Feature': , 'Label': }\")\n \nFor more details about the package, please refer to:\n\nhttps://docs.microsoft.com/en-us/nimbusml"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Resources\n- [NimbusML FastLinearClassifier](https://docs.microsoft.com/en-us/python/api/nimbusml/nimbusml.linear_model.fastlinearclassifier?view=nimbusml-py-latest)\n- [NimbusML LightGbmRegressor](https://docs.microsoft.com/en-us/python/api/nimbusml/nimbusml.ensemble.lightgbmregressor?view=nimbusml-py-latest)\n- [Machine Learning at Microsoft with ML.NET](https://arxiv.org/pdf/1905.05715.pdf)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}