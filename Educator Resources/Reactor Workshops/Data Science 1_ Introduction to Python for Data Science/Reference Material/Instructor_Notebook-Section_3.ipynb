{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introduction to Pandas\n\nHaving explored NumPy, it is time to get to know the other workhorse of data science in Python: pandas. The pandas library in Python really does a lot to make working with data--and importing, cleaning, and organizing it--so much easier that it is hard to imagine doing data science in Python without it.\n\nBut it was not always this way. Wes McKinney developed the library out of necessity in 2008 while at AQR Capital Management in order to have a better tool for dealing with data analysis. The library has since taken off as an open-source software project that has become a mature and integral part of the data science ecosystem. (In fact, some examples in this section will be drawn from McKinney's book, *Python for Data Analysis*.)\n\nThe name 'pandas' actually has nothing to do with Chinese bears but rather comes from the term *panel data*, a form of multi-dimensional data involving measurements over time that comes out the econometrics and statistics community. Ironically, while panel data is a usable data structure in pandas, it is not generally used today and we will not examine it in this course. Instead, we will focus on the two most widely used data structures in pandas: `Series` and `DataFrame`s."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Reminders about importing and documentation\n\nJust as you imported NumPy undwither the alias ``np``, we will import Pandas under the alias ``pd``:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As with the NumPy convention, `pd` is an important and widely used convention in the data science world; we will use it here and we advise you to use it in your own coding.\n\nAs we progress through Section 5, don't forget that IPython provides tab-completion feature and function documentation with the ``?`` character. If you don't understand anything about a function you see in this section, take a moment and read the documentation; it can help a great deal. As a reminder, to display the built-in pandas documentation, use this code:\n\n```ipython\nIn [4]: pd?\n```\n\nBecause it can be useful to lean about `Series` and `DataFrame`s in pandas a extension of `ndarray`s in NumPy, go ahead also import NumPy; you will want it for some of the examples later on:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, on to pandas!"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Fundamental panda data structures\n\nBoth `Series` and `DataFrame`s are a lot like they `ndarray`s you encountered in the last section. They provide clean, efficent data storage and handling at the scales necessary for data science. What both of them provide that `ndarray`s lack, however, are essential data-science features like flexibility when dealing with missing data and the ability to label data. These capabilities (along with others) help make `Series` and `DataFrame`s essential to the \"data munging\" that make up so much of data science."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### `Series` objects in pandas\n\nA pandas `Series` is a lot like an `ndarray` in NumPy: a one-dimensional array of indexed data.\nYou can create a simple Series from an array of data like this:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example = pd.Series([-0.5, 0.75, 1.0, -2])\nseries_example",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Similar to an `ndarray`, a `Series` upcasts entries to be of the same type of data (that `-2` integer in the original array became a `-2.00` float in the `Series`).\n\nWhat is different from an `ndarray` is that the ``Series`` automatically wraps both a sequence of values and a sequence of indices. These are two separate objects within the `Seriers` object that can access with the ``values`` and ``index`` attributes.\n\nTry accessing the ``values`` first; they are just a familiar NumPy array:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The ``index`` is also an array-like object:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example.index",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Just as with `ndarra`s, you can access specific data elements in a `Series` via the familiar Python square-bracket index notation and slicing:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example[1:3]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Despite a lot of similarities, pandas `Series` have an important distinction from NumPy `ndarrays`: whereas `ndarrays` have  *implicitly defined* integer indices (as do Python lists), pandas `Series` have *explicitly defined* indices. The best part is that you can set the index:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2 = pd.Series([-0.5, 0.75, 1.0, -2], index=['a', 'b', 'c', 'd'])\nseries_example2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "These explicit indices work exactly the way you would expect them to:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2['b']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Exercise:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Do explicit Series indices work *exactly* the way you might expect?\n# Try slicing series_example2 using its explicit index and find out.\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "With explicit indices in the mix, a `Series` is basically a fixed-length, ordered dictionary in that it maps arbitrary typed index values to arbitrary typed data values. But like `ndarray`s these data are all of the same type, which is important. Just as the type-specific compiled code behind `ndarray` makes them more efficient than a Python lists for certain operations, the type information of pandas ``Series`` makes them much more efficient than Python dictionaries for certain operations.\n\nBut the connection between `Series` and dictionaries is nevertheless very real: you can construct a ``Series`` object directly from a Python dictionary:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "population_dict = {'France': 65429495,\n                   'Germany': 82408706,\n                   'Russia': 143910127,\n                   'Japan': 126922333}\npopulation = pd.Series(population_dict)\npopulation",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Did you see what happened there? The order of the keys `Russia` and `Japan` in the switched places between the order in which they were entered in `population_dict` and how they ended up in the `population` `Series` object. While Python dictionary keys have no order, `Series` keys are ordered.\n\nSo, at one level, you can interact with `Series` as you would with dictionaries:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "population['Russia']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "But you can also do powerful array-like operations with `Series` like slicing:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Try slicing on the population Series on your own.\n# Would slicing be possible if Series keys were not ordered?\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also add elements to a `Series` the way that you would to an `ndarray`. Try it in the code cell below:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Try running population['Albania'] = 2937590 (or another country of your choice)\n# What order do the keys appear in when you run population? Is it what you expected?\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Anoter useful `Series` feature (and definitely a difference from dictionaries) is that `Series` automatically aligns differently indexed data in arithmetic operations:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pop2 = pd.Series({'Spain': 46432074, 'France': 102321, 'Albania': 50532})\npopulation + pop2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Notice that in the case of Germany, Japan, Russia, and Spain (and Albania, depending on what you did in the previous exercise), the addition operation produced `NaN` (not a number) values. pandas does not treat missing values as `0`, but as `NaN` (and it can be helpful to think of arithmetic operations involving `NaN` as essentially `NaN`$ + x=$ `NaN`)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### `DataFrame` object in pandas\n\nThe other crucial data structure in pandas to get to know for data science is the `DataFrame`.\nLike the ``Series`` object, ``DataFrame``s can be thought of either as generalizations of `ndarray`s (or as specializations of Python dictionaries).\n\nJust as a ``Series`` is like a one-dimensional array with flexible indices, a ``DataFrame`` is like a two-dimensional array with both flexible row indices and flexible column names. Essentially, a `DataFrame` represents a rectangular table of data and contains an ordered collection of labeled columns, each of which can be a different value type (`string`, `int`, `float`, etc.).\nThe DataFrame has both a row and column index; in this way you can think of it as a dictionary of `Series`, all of which share the same index.\n\nLet's take a look at how this works in practice. We will start by creating a `Series` called `area`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "area_dict = {'Albania': 28748,\n             'France': 643801,\n             'Germany': 357386,\n             'Japan': 377972,\n             'Russia': 17125200}\narea = pd.Series(area_dict)\narea",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now you can combine this with the `population` `Series` you created earlier by using a dictionary to construct a single two-dimensional table containing data from both `Series`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries = pd.DataFrame({'Population': population, 'Area': area})\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As with `Series`, note that `DataFrame`s also automatically order indices (in this case, the column indices `Area` and `Population`).\n\nSo far we have combined dictionaries together to compose a `DataFrame` (which has given our `DataFrame` a row-centric feel), but you can also create `DataFrame`s in a column-wise fashion. Consider adding a `Capital` column using our reliable old array-analog, a list:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['Capital'] = ['Tirana', 'Paris', 'Berlin', 'Tokyo', 'Moscow']\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As with `Series`, even though initial indices are ordered in `DataFrame`s, subsequent additions to a `DataFrame` stay in the ordered added. However, you can explicitly change the order of `DataFrame` column indices this way:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries = countries[['Capital', 'Area', 'Population']]\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Commonly in a data science context, it is necessary to generate new columns of data from existing data sets. Because `DataFrame` columns behave like `Series`, you can do this is by performing operations on them as you would with `Series`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['Population Density'] = countries['Population'] / countries['Area']\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note: don't worry if IPython gives you a warning over this. The warning is IPython trying to be a little too helpful. The new column you created is an actual part of the `DataFrame` and not a copy of a slice."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We have stated before that `DataFrame`s are like dictionaries, and it's true. You can retrieve the contents of a column just as you would the value for a specific key in an ordinary dictionary:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['Area']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "What about using the row indices?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now try accessing row data with a command like countries['Japan']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This returns an error: `DataFrame`s are dictionaries of `Series`, which are the columns. `DataFrame` rows often have heterogeneous data types, so different methods are necessary to access row data. For that, we use the `.loc` method:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.loc['Japan']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that what `.loc` returns is an indexed object in its own right and you can access elements within it using familiar index syntax:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.loc['Japan']['Area']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Can you think of a way to return the area of Japan without using .iloc?\n# Hint: Try putting the column index first.\n# Can you slice along these indices as well?\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Sometimes it is helpful in data science projects to add a column to a `DataFrame` without assigning values to it:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['Debt-to-GDP Ratio'] = np.nan\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Again, you can disregard the warning (if it triggers) about adding the column this way.\n\nYou can also add columns to a `DataFrame` that do not have the same number of rows as the `DataFrame`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "debt = pd.Series([0.19, 2.36], index=['Russia', 'Japan'])\ncountries['Debt-to-GDP Ratio'] = debt\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can use the `del` command to delete a column from a `DataFrame`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "del countries['Capital']\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In addition to their dictionary-like behavior, `DataFrames` also behave like two-dimensional arrays. For example, it can be useful at times when working with a `DataFrame` to transpose it:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Again, note that `DataFrame` columns are `Series` and thus the data types must consistent, hence the upcasting to floating-point numbers. **If there had been strings in this `DataFrame`, everything would have been upcast to strings.** Use caution when transposing `DataFrame`s."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### From a two-dimensional NumPy array\n\nGiven a two-dimensional array of data, we can create a ``DataFrame`` with any specified column and index names.\nIf omitted, an integer index will be used for each:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pd.DataFrame(np.random.rand(3, 2),\n             columns=['foo', 'bar'],\n             index=['a', 'b', 'c'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Manipulating data in pandas\n\nA huge part of data science is manipulating data in order to analyze it. (One rule of thumb is that 80% of any data science project will be concerned with cleaning and organizing the data for the project.) So it makes sense to lear the tools that pandas provides for handling data in `Series` and especially `DataFrame`s. Because both of those data structures are ordered, let's first start by taking a closer look at what gives them their structure: the `Index`."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Index objects in pandas\n\nBoth ``Series`` and ``DataFrame``s in pandas have explicit indices that enable you to reference and modify data in them. These indices are actually objects themselves. The ``Index`` object can be thought of as both an immutable array or as fixed-size set. \n\nIt's worth the time to get to know the properties of the `Index` object. Let's return to an example from earlier in the section to examine these properties."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example = pd.Series([-0.5, 0.75, 1.0, -2], index=['a', 'b', 'c', 'd'])\nind = series_example.index\nind",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The ``Index`` works a lot like an array. we have already seen how to use standard Python indexing notation to retrieve values or slices:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ind[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ind[::2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "But ``Index`` objects are immutable; you cannot be modified via the normal means:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ind[1] = 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This immutability is a good thing: it makes it safer to share indices between multiple ``Series`` or ``DataFrame``s without the potential for problems arising from inadvertent index modification."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In addition to being array-like, a Index also behaves like a fixed-size set, including following many of the conventions used by Python's built-in ``set`` data structure, so that unions, intersections, differences, and other combinations can be computed in a familiar way. Let's play around with this to see it in action."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ind_odd = pd.Index([1, 3, 5, 7, 9])\nind_prime = pd.Index([2, 3, 5, 7, 11])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the code cell below, try out the intersection (`ind_odd & ind_prime`), union (`ind_odd | ind_prime`), and the symmetric difference (`ind_odd ^ ind_prime`) of `ind_odd` and `ind_prime`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "These operations may also be accessed via object methods, for example ``ind_odd.intersection(ind_prime)``. Below is a table listing some useful `Index` methods and properties."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "| **Method**     | **Description**                                                                           |\n|:---------------|:------------------------------------------------------------------------------------------|\n| [`append`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html)       | Concatenate with additional `Index` objects, producing a new `Index`                      |\n| [`diff`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html)         | Compute set difference as an Index                                                        |\n| [`drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)         | Compute new `Index` by deleting passed values                                             |\n| [`insert`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.insert.html)       | Compute new `Index` by inserting element at index `i`                                     |\n| [`is_monotonic`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.is_monotonic.html) | Returns `True` if each element is greater than or equal to the previous element           |\n| [`is_unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.is_unique.html)    | Returns `True` if the Index has no duplicate values                                       |\n| [`isin`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html)         | Compute boolean array indicating whether each value is contained in the passed collection |\n| [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html)       | Compute the array of unique values in order of appearance                                         |"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Data Selection in Series\n\nAs a refresher, a ``Series`` object acts in many ways like both a one-dimensional `ndarray` and a standard Python dictionary.\n\nLike a dictionary, the ``Series`` object provides a mapping from a collection of arbitrary keys to a collection of arbitrary values. Back to an old example:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2 = pd.Series([-0.5, 0.75, 1.0, -2], index=['a', 'b', 'c', 'd'])\nseries_example2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2['b']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also examine the keys/indices and values using dictionary-like Python tools:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "'a' in series_example2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2.keys()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "list(series_example2.items())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As with dictionaries, you can extend a dictionary by assigning to a new key, you can extend a ``Series`` by assigning to a new index value:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2['e'] = 1.25\nseries_example2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Series as one-dimensional array\n\nBecause ``Series`` also provide array-style functionality, you can use the NumPy techniques we looked at in Section 3 like slices, masking, and fancy indexing:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Slicing using the explicit index\nseries_example2['a':'c']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Slicing using the implicit integer index\nseries_example2[0:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Masking\nseries_example2[(series_example2 > -1) & (series_example2 < 0.8)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Fancy indexing\nseries_example2[['a', 'e']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "One note to avoid confusion. When slicing with an explicit index (i.e., ``series_example2['a':'c']``), the final index is **included** in the slice; when slicing with an implicit index (i.e., ``series_example2[0:2]``), the final index is **excluded** from the slice."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Indexers: `loc` and `iloc`\n\nA great thing about pandas is that you can use a lot different things for your explicit indices. A potentially confusing thing about pandas is that you can use a lot different things for your explicit indices, including integers. To avoid confusion between integer indices that you might supply and those implicit integer indices that pandas generates, pandas provides special *indexer* attributes that explicitly expose certain indexing schemes.\n\n(A technical note: These are not functional methods; they are attributes that expose a particular slicing interface to the data in the ``Series``.)\n\nThe ``loc`` attribute allows indexing and slicing that always references the explicit index:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2.loc['a']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2.loc['a':'c']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The ``iloc`` attribute enables indexing and slicing using the implicit, Python-style index:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2.iloc[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series_example2.iloc[0:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "A guiding principle of the Python language is the idea that \"explicit is better than implicit.\" Professional code will generally use explicit indexing with ``loc`` and ``iloc`` and you should as well in order to make your code clean and readable."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Data selection in DataFrames\n\n``DataFrame``s also exhibit dual behavior, acting both like a two-dimensional `ndarray` and like a dictionary of ``Series``  sharing the same index."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### DataFrame as dictionary of Series\n\nLet's return to our earlier example of countries' areas and populations in order to examine `DataFrame`s as a dictionary of `Series`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "area = pd.Series({'Albania': 28748,\n                  'France': 643801,\n                  'Germany': 357386,\n                  'Japan': 377972,\n                  'Russia': 17125200})\npopulation = pd.Series ({'Albania': 2937590,\n                         'France': 65429495,\n                         'Germany': 82408706,\n                         'Russia': 143910127,\n                         'Japan': 126922333})\ncountries = pd.DataFrame({'Area': area, 'Population': population})\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can access the individual ``Series`` that make up the columns of a ``DataFrame`` via dictionary-style indexing of the column name:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['Area']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "An you can use dictionary-style syntax can also be used to modify `DataFrame`s, such as by adding a new column:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['Population Density'] = countries['Population'] / countries['Area']\ncountries",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### DataFrame as two-dimensional array\n\nYou can also think of ``DataFrame``s as two-dimensional arrays. You can examine the raw data in the `DataFrame`/data array using the ``values`` attribute:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Viewed thsi way it makes sense that we can transpose the rows and columns of a `DataFrame` the same way we would an array:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "`DataFrame`s also uses the ``loc`` and ``iloc`` indexers. With ``iloc``, you can index the underlying array as if it were an `ndarray` but with the ``DataFrame`` index and column labels maintained in the result:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.iloc[:3, :2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "``loc`` also permits array-like slicing but using the explicit index and column names:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries.loc[:'Germany', :'Population']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "You can also use array-like techniques such as masking and fancing indexing with `loc`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Can you think of how to combine masking and fancy indexing in one line?\n# Your masking could be somthing like countries['Population Density'] > 200\n# Your fancy indexing could be something like ['Population', 'Population Density']\n# Be sure to put the the masking and fancy indexing inside the square brackets: countries.loc[]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Indexing conventions\n\nIn practice in the world of data science (and pandas more generally), *indexing* refers to columns while *slicing* refers to rows:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries['France':'Japan']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Such slices can also refer to rows by number rather than by index:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries[1:3]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Similarly, direct masking operations are also interpreted row-wise rather than column-wise:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countries[countries['Population Density'] > 200]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "These two conventions are syntactically similar to those on a NumPy array, and while these may not precisely fit the mold of the Pandas conventions, they are nevertheless quite useful in practice."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Operating on Data in Pandas\n\nAs you begin to work in data science, operating on data is imperative. It is the very heart of data science. Another aspect of pandas that makes it a compelling tool for many data scientists is pandas' capability to perform efficient element-wise operations on data. pandas builds on ufuncs from NumPy to supply theses capabilities and then extends them to provide additional power for data manipulation:\n - For unary operations (such as negation and trigonometric functions), ufuncs in pandas **preserve index and column labels** in the output.\n - For binary operations (such as addition and multiplication), pandas automatically **aligns indices** when passing objects to  ufuncs.\n\nThese critical features of ufuncs in pandas mean that data retains its context when operated on and, more importantly still, drastically helps reduce errors when you combine data from multiple sources."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Index Preservation\n\npandas is explicitly designed to work with NumPy. As a results, all NumPy ufuncs will work on Pandas ``Series`` and ``DataFrame`` objects.\n\nWe can see this more clearly if we create a simple ``Series`` and ``DataFrame`` of random numbers on which to operate. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "rng = np.random.RandomState(42)\nser_example = pd.Series(rng.randint(0, 10, 4))\nser_example",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Did you notice the NumPy function we used with the variable `rng`? By specifying a seed for the random-number generator, you get the same result each time. This can be useful trick when you need to produce psuedo-random output that also needs to be replicatable by others. (Go ahead and re-run the code cell above a couple of times to convince yourself that it produces the same output each time.)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_example = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n                  columns=['A', 'B', 'C', 'D'])\ndf_example",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's apply a ufunc to our example `Series`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "np.exp(ser_example)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The same thing happens with a slightly more complex operation on our example `DataFrame`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "np.cos(df_example * np.pi / 4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that you can use all of the ufuncs we discussed in Section 3 the same way."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Index alignment\n\nAs mentioned above, when you perform a binary operation on two ``Series`` or ``DataFrame`` objects, pandas will align indices in the process of performing the operation. This is essential when working with incomplete data (and data is usually incomplete), but it is helpful to see this in action to better understand it."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Index alignment with Series\n\nFor our first example, suppose we are combining two different data sources and find only the top five countries by *area* and the top five countries by *population*:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "area = pd.Series({'Russia': 17075400, 'Canada':  9984670,\n                  'USA': 9826675, 'China': 9598094, \n                  'Brazil': 8514877}, name='area')\npopulation = pd.Series({'China': 1409517397, 'India': 1339180127,\n                        'USA': 324459463, 'Indonesia': 322179605, \n                        'Brazil': 207652865}, name='population')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now divide these to compute the population density\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Your resulting array contains the **union** of indices of the two input arrays: seven countries in total. All of the countries in the array without an entry (because they lacked either area data or population data) are marked with the now familiar ``NaN``, or \"Not a Number,\" designation.\n\nIndex matching works the same way built-in Python arithmetic expressions and missing values are filled in with `NaN`s. You can see this clearly by adding two `Series` that are slightly misaligned in their indices:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series1 = pd.Series([2, 4, 6], index=[0, 1, 2])\nseries2 = pd.Series([3, 5, 7], index=[1, 2, 3])\nseries1 + series2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "`NaN` values are not always convenient to work with; `NaN` combined with any other values results in `NaN`, which can be a pain, particulalry if you are combining multiple data sources with missing values. To help with this, pandas allows you to specify a default value to use for missing values in the operation. For example, calling `series1.add(series2)` is equivalent to calling `series1 + series2`, but you can supply the fill value:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "series1.add(series2, fill_value=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Much better!"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Index alignment with DataFrames\n\nThe same kind of alignment takes place in both dimension (columns and indices) when you perform operations on ``DataFrame``s."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df1 = pd.DataFrame(rng.randint(0, 20, (2, 2)),\n                   columns=list('AB'))\ndf1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df2 = pd.DataFrame(rng.randint(0, 10, (3, 3)),\n                   columns=list('BAC'))\ndf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Add df1 and df2. Is the output what you expected?",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Even though we passed the columns in a different order in `df2` than in `df1`, the indices were aligned correctly sorted in the resulting union of columns.\n\nYou can also use fill values for missing values with `Data Frame`s. In this example, let's fill the missing values with the mean of all values in `df1` (computed by first stacking the rows of `df1`):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fill = df1.stack().mean()\ndf1.add(df2, fill_value=fill)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This table lists Python operators and their equivalent pandas object methods:\n\n| Python Operator | Pandas Method(s)                      |\n|-----------------|---------------------------------------|\n| ``+``           | ``add()``                             |\n| ``-``           | ``sub()``, ``subtract()``             |\n| ``*``           | ``mul()``, ``multiply()``             |\n| ``/``           | ``truediv()``, ``div()``, ``divide()``|\n| ``//``          | ``floordiv()``                        |\n| ``%``           | ``mod()``                             |\n| ``**``          | ``pow()``                             |\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Operations between DataFrames and Series\n\nIndex and column alignment gets maintained in operations between a `DataFrame` and a `Series` as well. To see this, consider a common operation in data science, wherein we find the difference of a `DataFrame` and one of its rows. Because pandas inherits ufuncs from NumPy, pandas will compute the difference row-wise by default:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3 = pd.DataFrame(rng.randint(10, size=(3, 4)), columns=list('WXYZ'))\ndf3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3 - df3.iloc[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "But what if you need to operate column-wise? You can do this by using object methodsand specifying the ``axis`` keyword."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3.subtract(df3['X'], axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And when you do operations between `DataFrame`s and `Series` operations, you still get automatic index alignment:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "halfrow = df3.iloc[0, ::2]\nhalfrow",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that the output from that operation was transposed. That was so that we can subtract it from the `DataFrame`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3 - halfrow",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Remember, pandas preserves and aligns indices and columns so preserve data context. This will be of huge help to you in our next section when we look at data cleaning and preparation."
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}