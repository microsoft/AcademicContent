# Imagine Cup Junior 
# Virtual AI Hackathon

Figure 1. Our Biosphere. Image source, Shutterstock
Learning Content 

Preparation
- Hackathon Introduction
    - Learning About AI
    - Structure
    - Timetable
- How To Use The Platform
    - Code of conduct
    - Identities And Groups
    - Platform Requirements
    - Platform Use
- Pathways to an AI Career
- Levelling-up Exercises
    - Earth’s Energy Budget Model in Python
    - Cyber Security Coding Task
    - Coding a ‘Decision Tree‘ Algorithm
- AI For Earth
- Checkpoint 1
- Checkpoint 1 (Answers)
DAY 1, AM
- Technical Setup
    - Testing
- What Is AI?
    - Capabilities And Applications
    - Machine Learning
    - When Should Machine Learning be Used?
    - How Does Machine Learning Work?
- Regression
    - Predicting Water Consumption in Excel
- TEAM PRACTICAL TASK 1
    - Predicting Water Consumption in Python
    - Data
    - Model
    - Explore the Algorithm
- TEAM PRACTICAL TASK 2
    - EXTENSION TASK –
- What Did We Learn?
- Machine Learning Applications
    - Natural Language Processing
    - Recommendation Engines
    - Robots and RPA
    - Image Processing
- The AI Development Process
    - Define The Problem
    - Hypothesise
    - Prepare Data
    - Model Data
    - Deploy
- Classification - The KNN Model
- TEAM PRACTICAL TASK 3
- SDG Exploration 1 Instructions
    - Microsoft's Interactive AI Demos
    - UN SDGs + AI
DAY 1, PM
- Introduction to Trees
- Decision Trees in Python
    - General Principles
- TEAM PRACTICAL TASK 4
- A Day in the Life of an AI Practitioner
- Introduction To Forests
- TEAM PRACTICAL TASK 5
- TEAM PRACTICAL TASK 6
    - Extension Task
    - How does a Python Random Forest program work?
- SDG Exploration 2 Instructions
    - How Many Trees Do We Need to Plant?
- Checkpoint 2
DAY 2, AM
- Image Classification Introduction
    - How Does Image Classification Work?
- TEAM PRACTICAL TASK 7
    - How Does The Classifier Work?
- Image Classification Task
- TEAM PRACTICAL TASK 8
- Neural Networks
- Neural Networks Applied to a Problem
- Expanding a Neural Network’s Layers and Nodes
- Build a Neural Network in Excel
- TEAM PRACTICAL TASK 9
- SDG Exploration 3 Instructions
    - Endangered Species - Can AI Help?
Day 2, PM
- TEAM PRACTICAL TASK 10
    - Design Challenge Brief
    - Design A Web Service That Protects An Endangered Species
    - Present, And Participate In The Critique

## PREPARATION

### Hackathon Introduction
	
Whether you are aware of it or not, AI is affecting your daily life. If you use social media, purchase goods or services, buy food in supermarkets, vote, travel, work or study - AI is behind the scenes, ‘nudging’ your behaviours and shaping the world we live in. Therefore, AI is something which everyone needs to learn to navigate.

This hackathon is designed to help you become an AI protagonist - understand what AI is; learn how to adapt to a constantly changing intelligence landscape; and build skills that allow you to take ethical control of the development and use of AI.  

Through this hackathon you will be able to identify ways in which AI is contributing to you lives today; what applications should AI be used for; and how AI can be used to address some of the biggest challenges we face. 

This hackathon will help you gain the confidence to question digital media, Big Tech, big and small data, and government policy, and help create a more democratic Internet. You will master the basic mechanics of AI, learn how to frame AI problems, and understand the main concepts behind AI. 

Data collection, data cleaning, model choice, and statistical testing are all skills which are already in high demand, and are likely to become even more so as you prepare to enter the world of work. To comply with current and future AI regulations, being able to explain how the AI works (XAI), and where the data has come from is another valuable skill set that we will focus on in the Hackathon. 

By the end of the hackathon you will be clearer about potential AI-related career paths such as Data Scientists, AI specialists, or future AI leader. Some of the Maths and Computer Science, Design and System Thinking skills required to perform these roles, as well as an insight into what it’s like being an AI practitioner, will be covered on the hackathon. 

Overall, you will get the chance to gain a practical understanding of AI; learn how to harness it's power, become inspired to – and know how to – learn more. 

The theme of this hackathon is “AI for Earth”. The examples that we’ll use will focus on how AI can be used to better understand sustainability – particularly climate change and loss of biodiversity. 

Activities in this hackathon are linked to the relevant United Nations’ Sustainable Development Goals (SDGs). These are an urgent call to action by all countries - developed and developing - in a global partnership. They recognize that ending poverty and other deprivations must go hand-in-hand with strategies that improve health and education, reduce inequality, and spur economic growth – all while tackling climate change and working to preserve our oceans and forests.

Figure 2. UN's Sustainable Development Goals

#### Learning About AI
*Why Learn About AI?* 
 
Whilst you might not need to understand how an engine works to drive a car, or how a computer works in order to use one, AI is different. This is because AI is not a product, it's a field. This means that the choices of data, models, methods, software, coding languages, services and are vast and therefore the decision-making process for how to tackle different types of AI problems can be complex and for those wishing to work with AI or implement it, a basic understanding of some of the mechanics is an essential foundation. 

You can’t control what you don’t understand. Unless you understand AI and are able to control it you are likely to have AI done to you by someone else. 

#### **Learning Goals**
By the end of this hackathon, you'll be able to recognise what kind of problems are and aren't solvable with AI, and the main approaches, models are for turning data into actionable predictions. 

You will – 

**Explore** 
Work with some quick and easy online demos to get a feel for the capabilities of AI

**Build**
Take data, and apply machine learning code to it 

**Practice**
Learn how models work by changing parameters in code 

To ensure that everyone is included – regardless of technical competence – you will use Excel to help you gain an understanding of the ‘mechanics’ of Machine Learning – the ‘engine’ of AI. 

You will also work with Python which is becoming a 'must have' tool for Data Science. Python is easy and fast to learn, and 0-30 lines of Python code can validate most machine learning ideas. Python code can be incorporated into General Purpose Coding programs which means that you can build enterprise solutions which include python components. It also has many AI and data science libraries. 

Another key learning goal is for you to understand what career opportunities exist in the AI field, how to get there and what it’s like when you have become an AI practitioner. 

*Learning Pathway* 

Preparation for the hackathon involves introductory exercises in Excel and Python, and some guided background research into AI. 

On the morning of Day 1 of the hackathon we’ll cover the following topics - 
-	What is AI?
-	Classification  
-	The AI Development Process
-	Machine Learning Applications
-	Regression 
-	Predicting Demand for Fresh Water 

After the 2-hour formal part of Day 1, you will have time to study on your own or within your team. You will explore Interactive AI Demos and the United Nations Sustainable Goals and think about how AI can be used to achieve these goals. 

On the afternoon of Day 1, we’ll cover the following topics -  
-	Decision Trees in Action
-	Day in the Life of an AI Practitioner
-	Forests (using lots of decision trees together) 

After the formal part of Day 1, you will start to work on a problem involving real trees and forests, by answering the question “how many trees do we need to plant to mitigate climate change?” 
 
On the morning of Day 2, we’ll cover the following topics -  
-	Image Categorisation
-	Neural Networks

After this you will prepare for the Day 2 Design Challenge. 

On the afternoon of Day 2 you will work in teams to answer a design challenge, and build a short ‘pitch’ for a new product that applies AI to a sustainability problem to a group of ‘investors’.  

After this, you will be involved in critiquing the other teams’ pitches. 

*Objective*

The end goal of the hackathon is for you to produce an outline design of a web service that uses AI. This may sound complex, but you will be provided with the knowledge, skills and guidance to be able to do this. 

In the last session of the hackathon will have team presentations, and whilst other present you will ask questions and get to vote for the best design.
  
*Structure*

The hackathon lasts for 2 days. You will participate in a combination of lectures and teamwork, and on the afternoon of day 2 you will work on a practical team assignment.  
 
Figure 3. Hackathon timeline

Throughout, you will be working in a team of 5 people and your team will have a mentor who will help you work through the tasks. 

*Assessment*

Your engagement in the hackathon will be assessed using the following scoring model 
-	50% your test scores in a series of knowledge checks
-	50% your score in the team project – e.g. if you are in a team of 3 and the score is 30/50, each member of team gets 30/50. 

|  |  | Component | Mode | 
| ----------- | ----------- |----------- | ----------- |
|  | **Preparation** |  |  |
|  | Hackathon Introduction | Know what to do in the hackathon | Video |
|  | How to Use the Platform | Know how to access and use the platform | Video instructions |
|  | AI for Earth | Imagine Cup Junior | Text + video links |
|  | Pathways to an AI Career | 3 pathways - university, vocational education, start-up | Video |
|  | Levelling-up Exercises | Coding Tasks | Practical |
|  | Knowledge Check 1 | Check on what has been learned in the prep | Individual study |

|  |  |  |  | 
| ----------- | ----------- |----------- | ----------- |
|  | **Day 1 AM** |  |  |
| 9.00 | Technical setup | Teams and Azure Lab Services setup | Video and Q&A | 60 |
| 10.00 | What is AI? | Intro to AI and Machine Learning | Lecture | 10 |
| 10.10 | Regression | Presentation | Lecture | 5 |
| 10.15 | TEAM PRACTICAL TASK 1 | Practical - Water Demand predictions, Excel | Team practical | 15 |
| 10.30 | TEAM PRACTICAL TASK 2 | Practical - Water Demand predictions, Python | Team practical | 15 |
| 10.55 | Q&A | Q&A | Q&A | 5 |
| 11.00 | Break | - | - | 10 |
| 11.10 | Machine Learning Applications | Presentation | Lecture | 10 |
| 11.20 | The AI Development Process | Summary of how AI solutions are built | Lecture | 5 |
| 11.25 | TEAM PRACTICAL TASK 3 | Classification - The KNN Model | Team practical | 25 |
| 11.50 | What Did We Learn? | Learning check | Q&A and discussion | 5 |
| 11.55 | SDG Exploration 1 Instructions | Explain the exploration task | Lecture | 5 |
|  | **SDG Exploration 1** |  |  |  |
| 12.00 | Microsoft's Interactive AI Demos | Explore a range of interactive AI demos, focus on NLP | Experiment | 45 |
| 12.45 | UN SDGs + AI | What are the UN's SDGs? How can AI help meet them? | Research | 15 |
| 13.00 | Lunch | - | - | 60 |

|  |  |  |  | 
| ----------- | ----------- |----------- | ----------- |
|  | **Day 1 PM** |  |  |
| 14.00 | Review of SDG Exploration 1 | SDG Discussion. AI - Good or Bad? | Discussion | 5 |
| 14.05 | Introduction to Trees | Presentation | Lecture | 10 |
| 14.15 | TEAM PRACTICAL TASK 4 | - | - | 60 |
| 14.45 | Practical renewables investment - Python | Team | practical | 30 |
| 14.55 | Q&A | Q&A | Q&A | 10 |
| 15.05 | Day in the life of an AI Practitioner | Short presentation and Q&A | Q&A | 10 |
| 15.15 | Introduction to Forests | Random Forest Presentation | Lecture | 5 |
| 15.20 | TEAM PRACTICAL TASKS 5 & 6 | Coding Random Forests Practical - Python | Team practical | 30 |
| 15.55 | Summary / Q&A | What was learned? | Q&A | 5 |
| 16.00 | SDG Exploration 2 Instructions | Explain the exploration task | Lecture | 5 |
|  | **SDG Exploration 2** |  |  |  |
| 16.05 | How many trees do we need to plant? | Case study | Research | 40 |
| 16.45 | Knowledge Check 2 | Check on what has been learned in the prep | Individual study | 15 |

|  |  |  |  | 
| ----------- | ----------- |----------- | ----------- |
|  | **Day 2 AM** |  |  |
| 10.00 | SDG discussion - AI for tree planting | Review of SDG Exploration 2 | Discussion |  5 |
| 10.05 | Image Classification Introduction | Presentation | Lecture | 10 |
| 10.15 | TEAM PRACTICAL TASKS 7 & 8 |Working out where trees can be planted | Team practical | 45 |
| 11.00 | Break | - | - | 10 |
| 11.10 | Neural Networks	Presentation | - | Lecture | 10 |
| 11.20 | TEAM PRACTICAL TASK 9 | Build a Neural Network in Excel | Team practical | 30 |
| 11.50 | Summary / Q&A | What was learned? | Q&A and discussion | 5 |
| 11.55 | SDG Exploration 3 Instructions | Explain the exploration task | Lecture | 5 |
|  | **SDG Exploration 3** |  |  |  |
| 12.00 | Endangered Species - Can AI Help?	|  |  | 60 |
| 13.00 | Lunch | - | - | 60 |
 			 
|  |  |  |  | 
| ----------- | ----------- |----------- | ----------- |
|  | **Day 2 PM** |  |  |
| 14.00 | Design Challenge Brief | Challenge criteria | Lecture | 5 |
| 14.05 | TEAM PRACTICAL TASK 10 | Design and pitch a web service that protects an endangered species | Team practical | 50 |
| 14.55 | Present and critique | Evaluate design tasks | Team practical | 70 |
| 16.05 | Vote, winners announced and wrap | | Discussion | 15 |
| 16.20 | End | | | |


Table 1. AI for Earth Hackathon Timetable


## How To Use The Platform

### Code of conduct 
Code of Conducts are critical in helping every hackathon provide a harassment-free and respectful experience to every participant.  

You will have signed up to the following conditions when applying to join this hackathon – 

We expect every participant to demonstrate the following characteristics:
- Willingness to work in a team and negotiate, co-operate, find consensus
- A systematic approach to tasks
- Self-assessment and honest self-evaluation
- Awareness of the potential dangers of misusing materials and tools, in terms of personal health and safety and that of others
- Sensitivity for the effects of design and technological activity on the environment

You have also agreed to restrict your use of the Teams platform entirely within the boundaries of the learning tasks within the hackathon. In participating in this hackathon you have agreed that your use of the platform and the tools within it can be tracked if necessary. 

### Identities and Groups
You will be given a unique username and password to access this hackathon. 

It’s important to note that will be working as part of a team as well. Each team has been named after a significant contributor to AI and Computer Science. 

|  |  |  |  | 
| ----------- | ----------- |----------- | ----------- |
|  | **Day 2 PM** |  |  |
| 13.00 | Lunch | - | - | 60 |
| 13.00 | Lunch | - | - | 60 |
| 13.00 | Lunch | - | - | 60 |
| 13.00 | Lunch | - | - | 60 |

All Members Team Name	General						
							
Tutors	Mike Lloyd & John Curry
							
Team Names	Ada Lovelace	Alan Turing	Demis Hassabis	Fei-Fei Li	Geoffrey Hinton	Grace Hopper	Sofya Kovalevskaya
							
Members	scarlets 	bigideas 	snowman 	buddha 	princess 	bananasplit 	chickenbeans
	oatmeal 	poppins 	joe 	king 	entrepreneur 	chocolate 	heyyou
	hoosier 	explorer 	exotic 	queen 	scientist 	fury 	crazycat
	fastncurious 	fedora 	unsplash 	unfinishe 	mathematician 	athelete 	banana
	karma	yellow 	tropical 	Prince	tinfoil	coach	fluffycookie
Teacher/mentor	teacher1 	teacher2 	teacher3 	teacher4 	teacher5 	teacher6 	teacher7


Table 2. Teams and members

### Platform Requirements 
You will need a PC – laptop or desktop - running Windows or MacOS and a browser to engage in the hackathon. 

Tablets and phones are not suitable for this hackathon because the screen sizes are too small; you will need a keyboard; and a downloaded piece of software that you will need use will be incompatible with other types of devices. 

Figure 4. You will need a Windows 10 or Mac PC

You will be given three pieces of information. Make sure you keep make a note of these and keep this note safe. 

1. A long web address for the hackathon Teams site 
2. Your hackathon username 
3. Your hackathon password 

### Platform Use
There are 4 modes of working in the hackathon. You will use -  

1. Microsoft Teams running in a browser to communicate and collaborate with your tutors and teams, work through the hackathon guide, and undertake quizzes and assignments 
2. Excel Online to work on files in your team area in Teams 
3. Microsoft Remote Desktop application on your PC to connect with a Virtual Machine Running in the Cloud in order to run Python experiments 
4. PowerPoint Online to build a presentation with your team during the design challenge task 

Figure 5. The 4 modes of working in the hackathon

The first hour of the hackathon – 9.00 - 10.00AM is dedicated to technical setup. Please make sure that you arrive on time and carefully follow the instructions. 

This short video will help you prepare for the use of the platform - https://vimeo.com 

### Pathways to an AI Career

Figure 6. AI roles in a modern organisation

Modern organisations need people to lead AI in the organisation, people to manage AI projects, people who will use AI tools in their everyday work. Organisations also need to have savvy consumers for their products and services. 

Artificial Intelligence Index Report 2019 by Stanford University , claimed that 1.3% of jobs in the United States have AI in their title. 

So when thinking about potential future careers in AI, we need to consider a very wide range of activities and scenarios that take place in the modern organisation. 

So let’s explore different kinds of requirements related to these different roles – 

- **AI Leaders** - To take advantage of Artificial Intelligence, leaders need to understand how to frame AI within their organisation and guide its implementation and use. 
- **Data Scientists and Software Engineers** focus on building and engineering AI-based solutions to solve specific business problems identified by leaders.
- **Managers** need to be able to organise the delivery of AI-based services both internally and to customers, clients and partners – this bridges Data Science and Software Engineering with business and domain specialisms.  
- **Users** – people who use AI in the jobs. For example a HR specialist who uses AI to help select suitable candidates for a role, or a customer relations manager who uses AI to help with customer support 
- **Consumers** – those who use AI-based services provided by the organisation.  
- `Each of these different roles requires different types and different levels of knowledge and skills. 


Figure 7. Who should learn what?

So let’s look at the kinds of skills and knowledge required for different roles  

**Leaders**
*AI leaders can potentially come from Business and Management*
They need to be Tech savvy and have an appreciation of AI 
They need to have strategic & innovation mindset
They need to be capable of providing thought leadership 

**Data Scientists & Software Engineers**
*The relevant areas of study for this subset is Data Science, Comp Science & Maths, or at least a maths orientated subject* 
This group need to be able to frame AI problems 
They need very good statistics and probability skills 
They will need to be good at Programming, Data processing, Model building, and system design and implementation 

**Managers**
*Are likely to come from STEM areas of study*
They will need to be good at defining business problems, opportunities and project scopes
Visualising solutions, managing change and data story telling are all key skills for this group

**Users**
*There are no specific subject areas where this group is likely to come from* 
Users of AI systems should have a working understanding of statistics because it’s likely that they will have to explain the outcome of AI processes to other people 
To understand where predictions they will using come from, they need to have at least a basic understanding of machine learning  
Also, it would help a lot if this group had Computational thinking skills as well. 

**Consumers of AI will come from all subject areas** 
*Everyone needs to have an Informed scepticism about AI* 
Everyone will need to understand how AI can augment work and deliver the services they use 
They will also need to understand their own digital exhaust and how it feeds into AI systems, along with privacy, rights, data protection and an understanding of risks.

**Data Science Specialists**

Figure 8. What data science specialists need to know

At the top of the ‘subject specialism tree’, data science specialists and software engineers need data engineering data science and system engineering skills to build and deploy machine learning services.
 
The mindset that's required here is the application of new thinking from the world of computing to the more established world of mathematical methods and concepts. The intersect of these two disciplines is machine learning.

Figure 9. A potential career route into data science

One career path uncovered in a recent LinkedIn report is to upskill people already working closely with data towards becoming data scientists. 

One such group of “near AI” talent are data analysts who are already working on the first steps in the machine learning process. 

To move from analysing data to data science, learners will need to develop competencies in using the Python programming language and Python libraries such as NumPy, Pandas, Scikit-Learn, SciPy, and Matplotlib. They will also need to understand different kinds of models including Neural Networks.

## Levelling-up Exercises

The AI for Earth Hackathon will give you an opportunity to work with code and numbers. Whilst none of the tasks require you to be a coder or particularly strong in mathematics or science, it’s worth doing some exercises to get you ready for the practical activities in the hackathon. 

### Earth’s Energy Budget Model in Python  

A key topic for the AI for Earth hackathon is climate change. To understand climate change, we must understand how heat is regulated on planet Earth. Python makes this easy to understand and model, but let’s first frame the problem that we want Python to solve. For this, we need to do a little maths and physics, but don’t worry, Python will make the calculation part very easy. 

First let’s understand what is happening to our planet.  

Life on Earth relies on energy from the sun for warmth, photosynthesis and powering the water cycle and other essential life support cycles. But if the Earth retains too much energy from the sun, the planet would end up like Venus – uninhabitable.  

Earth’s temperature doesn’t infinitely rise because the surface and the atmosphere are simultaneously radiating heat to space. The temperature remains constant when the net flow of energy into and out of the Earth system is the same. This is known as the Earth’s energy budget . The energy budget can be explained by simple physics, and the law of Energy Conservation. 

When the flow of incoming solar energy is balanced by an equal flow of heat back out into space, Earth’s temperature is stable. Anything that increases or decreases the amount of incoming or outgoing energy causes a rise or fall in temperature.

Figure 10. Greenhouse gasses such as CO2 trap heat in the atmosphere

The amount of energy that radiates from Earth back into space is affected by two things:
1.	**Emissivity** - the ability of the Earth to release energy back into space. As Emissivity goes down, temperature goes up.
2.	**Albedo** - the ability of the Earth to reflect energy back into space – mainly from snow and ice. As Albedo goes down, temperature goes up. 

Figure 11. Earth's Energy Balance
As temperatures rise, ice and snow melts and the Albedo effect goes down. This in turn drives increased temperature. 

‘Ice-albedo feedback’ is a key aspect of global climate change. In the polar region, a decrease of snow and ice results in a decrease of surface albedo, and the intensified solar heating further decreases the snow and ice area .

The Earth’s Energy Budget can be expressed as 
Equation 1. Earth’s Energy Budget
…where the left-hand side represents the incoming energy from the Sun, and the right-hand side represents the outgoing energy from the Earth, and
•	**a** is the reflection of solar radiation at the surface, the Earths ‘albedo’, 0.3
•	**S** is the incoming energy from the sun per unit area, 1367 Wm2
•	**e** is the Earth’s effectiveness in emitting energy as thermal radiation, ‘emissivity’, which is a function of the composition of the atmosphere, 0.612
•	**o** is the ‘Stefan-Boltzmann Constant’ for increases in radiation as the temperature increases, 5.670367 × 10-8 kg s-3 K-4

Solving for temperature,

Equation 2. Solving the Earth’s Energy Budget for temperature

This gives us an average earth temperature of 15 °C  

To see how the equation works, copy the following code: 
```
Incoming_solar_radiation = S = 1367.0
StefanBoltzmann_Constant = o = 5.67e-8
Albedo = a = 0.3
Emissivity = e = 0.612
Outgoing_solar_radiation = Hout = S*(1-a)
Trapping_effect = E = 4*(e*o)
T = (Hout/E)**(1/4)
print (T-273.15)
```

Paste it into https://paiza.io/en/projects/new?language=python3 

Run it. 


Figure 12. You can model the Earth's energy equation in paiza.io

The answer should come out as: 14.9995996747. 

This approximates to the Earth’s current average near-surface temperature of 14.9 C. 

Next change the Albedo number from 0.3 to, say, 0.2. Note how the temperature rises significantly. 

Return Albedo to 0.3 and then reduce Emissivity to, say, 0.5. Again, note how the temperature rises. 

Clearly, reducing both Emissivity, Albedo together will significantly increase the temperature. 

If your model shows that reducing both Emissivity and Albedo increases temperature, then you have a working **model** for global warming. 

### Cyber Security Coding Task

For this next exercise, let’s change the subject completely. 

Behind every secure online activity are algorithms that encrypt data. The main method used in encryption is to test for divisibility – i.e., ‘is this number divisible by another given number or not’?

This code challenge is about re-configuring the jumbled-up Python code below, so it works as a divisibility tester.  

```
y = int(put your denominator here)
    print (x, "is divisible by", y,)
else:
x = int(put your numerator here)
if x % y == 0:
    print (x, "is not divisible by", y,)
```
#### Method 
1. Create a flow chart of how you think the program should work 

Figure 13. Flow chart

2. Produce “pseudocode” – code that can be used to sketch-out working code 
```
INPUT A VARIABLE x int(put your numerator here)
INPUT A VARIABLE y int(put your denominator here)
IF x % y == 0:
    OUTPUT (x, "is divisible by", y,)
ELSE:
    OUTPUT (x, "is not divisible by", y,)
```

3. General purpose coding language – Python 
```
x = int(put your numerator here)
y = int(put your denominator here)
if x % y == 0:
    print (x, "is divisible by", y,)
else:
    print (x, "is not divisible by", y,)
```

Copy, paste and run this code in https://paiza.io/en/projects/new?language=python3

When the code is run, it should look like this: 

Figure 14. Testing for divisibility with Python using Paiza.io

###Coding a 'Decision Tree' Algorithm 

A decision tree is a commonly used algorithm used in classification – an important Machine Learning topic. Example uses include: 
- Investment modelling
- Event location planning 
- Immunization awareness campaign planning
- How to increase tourist numbers to a city
- Managing flooding risks

Let’s now look at how we can code decision trees in Python using Python’s machine learning capabilities. 

Decision trees have flow-chart-like structures like this – 

This example is based on an irrigation system where a gate is opened to let water into a field when certain conditions are met – e.g. soil is dry and weather is hot. At the top, ‘root’, level we have information that defines what the decision tree is. 

Beneath this the tree splits into ‘nodes’. In the layer below the root we have nodes that contain the conditions “open” and “closed”. 

In the bottom row we have more nodes, each containing the conditions for the middle node above it being open or closed. 

In other words, in this case, for a gate to be ‘open’ it has to have two ‘yes’ in the bottom layer, and the opposite is true for ‘closed’. This will be used as our ‘training data’.  

We can think of the middle layer as ‘labels’ – i.e. open or closed. 

The goal of our Python machine-learning decision tree is to predict whether a gate should be open or closed – in other words, to predict the labels. 

We do this by inputting what we think the labels could be and running the algorithm which ‘learns’ the pattern from the ‘training data’ we give it. 

Of course, machine learning works with vast amounts of data, but this experiment which learns from a tiny amount of data illustrates the principles on which a machine learning decision tree works. 

Let’s now look at how the code works line by line. 

First, we import a decision tree machine learning library that does the calculation for us – 

`from sklearn import tree`

Next we convert the lock logic to numbers and bring in the data into our algorithm.   

In code, we set out the training data features as 

`X = [[1,1], [0,0]]` 

And the training data labels as

`Y = [1, 0]`  

Next we ‘call’ the decision tree and define it as a variable – “clf”. 

`clf = tree.DecisionTreeClassifier()`

Then we fit the training data to the labels. 

`clf = clf.fit(X, Y)`

Next we input ‘test data’. Here we input what we think the labels will be based on the training data that we have. Clearly, we can see both the training data and labels by looking at the data that we inputted for X and Y, but for now let’s ignore them and just work through the permutations logically. 

`labels_test=([1, 0])`

Here, the test that we will apply is the correct combination, so we should get a “1” answer meaning 100% correct. If, however, we reversed this the answer would be “0”. 

`labels_test=([0, 1])`

Logically, if we tried 1,1, we would be 50% right so the answer would be “0.5”. 

What would you expect to get from 0,0? 

The next two lines of code predicts Y based on X, then scores how accurate the test labels are.

```
clf.predict(X) 
score = clf.score(X, labels_test)
```

Finally we print the score: 

`print(score)` 

Now take this jumbled-up code, and write it in the right order into Paiza.io, then run it. 

```
clf = clf.fit(X, Y) 
Y = [1, 0] 
from sklearn import tree
X = [[1,1], [0,0]] 
clf.predict(X)
clf = tree.DecisionTreeClassifier()
print(score)
score = clf.score(X, labels_test)
labels_test=([0, 1])
```

Figure 15. Decision tree logic in Python

Next, use https://paiza.io/en/projects/new?language=python3 to 

1.	Try different combinations for ‘labels_test’ and see if it works. 
2.	Try different combinations of Y = and labels_test to see how they work. 

## AI For Earth

The context for this hackathon is the use of AI to help address climate change and biodiversity, and the practical work is focussed on helping solve these problems.

Due to the careless exploitation of the natural resources of Earth, biodiversity is in sharp decline . How often have you heard that species of animals and plants are facing extinction? Or forests are being cut down to create beef and soy farms, or palm oil plantations? Every living thing on Earth is part of an integrated ecosystem called the ‘Biosphere ’, and the Biosphere is being degraded by human activity. 

Adding to the biodiversity crisis is the climate crisis . Global warming is already driving people from their homes  through sea level rises and drought, contributing to massive wildfires and causing an increase in extreme weather events such as hurricanes and heatwaves. 

AI can help address the biodiversity and climate crises in a wide range of ways, and Microsoft’s AI for Good program is designed to do just that. By partnering with effective organisations across the world to deploy state of the art AI technology, Microsoft is helping to mitigate against biodiversity loss and climate change. Furthermore, Microsoft as an organisation is leading the world’s companies by committing to becoming carbon negative by 2030, and has embarked on a range of conservation measures such as conserving more water than it consumes , and committing to zero waste by 2030.

Microsoft is helping organisations around the world put AI to constructive and sustainable use. Their ‘AI for Good’ program  includes ‘AI for Earth,  ‘AI for Health’,  ‘AI for Accessibility’,  ‘AI for Humanitarian Action’ and AI for Cultural Heritage. 

In this hackathon, we will focus on Microsoft’s AI for Earth program which puts AI technology in the hands of those working to solve global climate and sustainability issues.

Let’s now look in more detail at some of Microsoft’s AI for Earth projects. 

#### Satellite Imagery For Forest Management

Our forests are an essential part of the biosphere, and have two key roles – firstly trees absorb CO2 and therefore are an essential component in addressing the climate crisis. Secondly, forests contain a myriad of plants, animals, birds, and insects and therefore are an essential component in addressing the biodiversity crisis. 

Our forests – including the Amazon, for example – are being destroyed at an unprecedented rate by wildfires, and destruction for beef, soy and palm oil farming. However, if managed effectively, forestry can be a key part in helping mitigate against climate change. Because trees absorb CO2, companies that emit CO2 can buy stakes in forests to ‘offset’ their CO2 emissions. These ‘carbon credits’ are traded between companies. 

It’s essential, therefore, that those managing forests are able to predict tree stock levels, how forests will develop, and use data to help manage forests better. AI can help by enabling forestry managers to predict the outcomes of different forestry management techniques and make better management decisions. 

SilviaTerra , a forest management organisation, partners with Microsoft in the AI for Earth program to use AI to analyse high-resolution satellite imagery of forests and predict future scenarios. SilviaTerra’s forestry management expertise combined with remote sensing, satellite imaging, big data and AI helps ensure the forests they manage are fully understood and valued correctly.

Figure 16. Using Satellite imagery for forest management

Watch SilviaTerra’s video here: https://youtu.be/stNlw_CFklc 

#### Sustainability for Global Fishing

According to the University of British Columbia , “countries drastically under report the number of fish caught worldwide”. The 2016 report in Nature Communications , estimates that 32 million metric tons of fish goes unreported every year – “more than the weight of the entire population of the United States”.

 Figure 17. AI can be used for protecting fish stocks

Not surprisingly, overfishing leads to declines in fish stocks , which in turn threatens food security and the livelihoods of those working in the world’s fishing industries. Pollutants, such as plastic waste, and global warming are also adding pressure to fish stocks . 

However, improved fisheries management can help make fishing sustainable. One organisation that is helping make fishing sustainable is OceanMind . Using satellites and artificial intelligence, OceanMind empowers fisheries authorities and seafood buyers to understand the compliance of fishing around the world. 

Figure 18. Tracking legal and illegal fishing using AI

OceanMind partners with Microsoft and government agencies to protect fishing stock, help preserve biodiversity, and protect livelihoods in the seafood industry. It does this by tracking fishing vessel’s positions at sea in real-time. They use sophisticated AI to analyse fishing vessel’s movements and identify suspicious behaviour. This could include, for example, staying in one place for too long; venturing into an area of water where fishing is not permitted; or deviating from an established route. 

Watch the videos here - https://www.oceanmind.global/microsoft/

#### Sustainable Agriculture  

There is ever-increasing pressure on agriculture to produce more food for a growing population, and to do this both profitably and sustainably. 

Part of the answer to this problem is use of more data to give farmers better insights on which to base their decisions. 

One example is from Ag-Analytics® which partnered with Microsoft to collect data from tractor sensors, satellites, and remote sensors to give farmers an accurate, actionable picture of their land. Ag-Analytics® enables farmers to access detailed data and precise information about their land, enabling them to farm the land more sustainably.

Figure 19. Using AI to make farming more sustainable

Another Microsoft AI for Earth partner, Agrimetrics, takes a similar approach. It operates a global ‘Data Marketplace’ that connects data and food and farming organisations to help create a more productive and sustainable global food system.

Global food businesses share data from sensors, satellite imagery, and historical datasets on the Data Marketplace. AI helps link sets of data. With the data all in one place, farmers can find insights from across the world to address their challenges.

Figure 20. Using AI to make farming more sustainable

Cloud Agronomics uses AI to provide growers with insights from high resolution images into their crops and soil. Their ‘carbon index services’ enables ‘carbon farming’ – the financially incentivised removal of carbon from the atmosphere and its storage in the soil, to aid plant growth. 

Figure 21. Using AI to make farming more sustainable

#### AI And Climate Change 

Climate change is the biggest challenge facing mankind and there are several ways in which AI can be used to mitigate against it. 

There are several key areas where AI can help – 
- Give people tools to reduce their personal carbon footprints
- Better climate and extreme weather models
- Improved measurement and predictions – e.g. predicting where rain forest is lost 
- Analysis of remote sensing data  
- Better electricity systems – use AI to better match demand and generation 
- Create new low-carbon materials that reduce the need for concrete and steel production
- Smarter cities for optimised traffic flow  
- Predict and control heating and cooling systems  
- Autonomous vehicles using AI can reduce fuel consumption  
- Optimised food supply chains and improved agricultural yields  
- Improve manufacturing efficiency  

## Checkpoint 1  

1. Why is it critical to understand how AI works? 

AI practitioners make a lot of money
AI is affecting my daily life
To know how to influence people  

2. The end goal of the hackathon is for you to  

Score as much as possible in the knowledge checks
Produce an outline design of a web service that uses AI 
Learn how to code 

3. Which of the following is not a learning goal of this hackathon? 

Recognise what kind of problems are and aren't solvable with AI 
Understand the main approaches and models for turning data into predictions  
Learn how to write machine learning code from scratch

4. I will be working in a team of 

3 people 
5 people 
5 people with a mentor 
10 people 
4 people 

5. Which of the following topics will not be covered on Day 1. Select both that apply. 

Interactive AI Demos
Decision Trees in Action
Image categorisation
Regression
The AI Development Process
Classification  
What is AI?
Predicting Demand for Fresh Water
Neural Networks
Machine Learning Applications
Forests (machine learning method)  
Day in the life of an AI Practitioner
United Nations Sustainable Goals 

6. Which of the following will be covered on day 2 – select all four that apply: 

Image categorisation
Design project
Regression
What is AI?
Critique 
United Nations Sustainable Goals
Classification  
Forests (machine learning method)  
Day in the life of an AI Practitioner
Neural Networks

7. Your engagement in the hackathon will be assessed using the following scoring model:

10% your knowledge check scores, 90% your score in the team project
50% your knowledge check scores, 50% your score in the team project
90% your knowledge check scores, 10% your score in the team project
70% your knowledge check scores, 30% your score in the team project
30% your knowledge check scores, 70% your score in the team project

8. Which of the following is not a mode of working on the AI hackathon platform 

Microsoft Remote Desktop application on your PC to connect with a Virtual Machine 
PowerPoint Online to build a presentation 
Microsoft Teams running in a browser to communicate and collaborate 
Excel Online to work on files in your team area in Teams 
Writing an essay about AI using Microsoft Word

9. Which of the following 3 pieces of information will you receive to access the hackathon 

Username 
Form to fill in
Password 
URL for Teams site 
Quantum encryption codes


10. When you log into Teams is important that you use the Teams

Remote Desktop
Web app – browser based
Desktop app
Windows or Mac app
API

11. The two main crises covered by the AI for Earth program, and will focus of this hackathon are:  

Covid 19
Climate change 
Biodiversity decline 
Misinformation 
Cyber security

12. OceanMind uses satellites and artificial intelligence to help governments understand

Fish stocks
What fishing quotas should be
The effects of pollution on fish stocks 
The effects of global warming on fish stocks
Illegal fishing 

13. AI can help by enabling forestry managers to predict 

How many trees are needed for paper production
How much rain is likely to fall on their forests 
The effects of market prices for paper
The outcomes of different forestry management techniques  
How new machines can help cut down trees 

14. The ethical use of AI in agriculture can help farmers 

Breed more cattle 
Make better sustainability decisions 
Grow more soy
Select which parts of forestry to turn into cattle farms 
Grow more palm oil trees

15. Which of the following is not an example of where AI can help tackle climate change

Create new low-carbon materials that reduce the need for concrete and steel production
Better climate and extreme weather models
Optimised food supply chains and improved agricultural yields  
Monitoring illegal fishing
Improve manufacturing efficiency  

16. Which three of the following skills and attributes should an AI leader have 

An appreciation of AI 
Tech savvy 
Model building 
Data processing 
Strategic & innovation mindset
Programming 
Thought leadership 
System design and implementation

17. Which four of the following skills and attributes should a Data Scientists and Software Engineers have

System design and implementation 
Data processing 
Defining business problems
Thought leadership 
Managing change 
Data story telling
Model building 
Programming

18. In the Earth’s Energy Budget Python model, reducing both Emissivity, Albedo together

Increases ice cover
Cools the Earth
Significantly increases the temperature of the Earth
Enables more energy to flow into space
Has no effect on the Earth’s temperature


19. A key method for securing transactions electronically is to test for 

Hacking
Fraud 
Ciphers 
Divisibility
Encryption 

20. Decision trees have structures resembling 

Trees
Flow charts 
Forests 
Buildings
Neural Networks

## Checkpoint 1 (Answers)

1. Why is it critical to understand how AI works? 

AI practitioners make a lot of money
**AI is affecting my daily life**
To know how to influence people  

2. The end goal of the hackathon is for you to  

Score as much as possible in the knowledge checks
**Produce an outline design of a web service that uses AI** 
Learn how to code 

3. Which of the following is not a learning goal of this hackathon? 

Recognise what kind of problems are and aren't solvable with AI 
Understand the main approaches and models for turning data into predictions  
**Learn how to write machine learning code from scratch**

4. I will be working in a team of 

3 people 
5 people 
**5 people with a mentor**
10 people 
4 people 

5. Which of the following topics will not be covered on Day 1. Select both that apply. 

Interactive AI Demos
Decision Trees in Action
**Image categorisation**
Regression
The AI Development Process
Classification  
What is AI?
Predicting Demand for Fresh Water
**Neural Networks**
Machine Learning Applications
Forests (machine learning method)  
Day in the life of an AI Practitioner
United Nations Sustainable Goals 

6. Which of the following will be covered on day 2 – select all four that apply: 

**Image categorisation**
**Design project**
Regression
What is AI?
**Critique** 
United Nations Sustainable Goals
Classification  
Forests (machine learning method)  
Day in the life of an AI Practitioner
**Neural Networks**

7. Your engagement in the hackathon will be assessed using the following scoring model:

10% your knowledge check scores, 90% your score in the team project
**50% your knowledge check scores, 50% your score in the team project**
90% your knowledge check scores, 10% your score in the team project
70% your knowledge check scores, 30% your score in the team project
30% your knowledge check scores, 70% your score in the team project

8. Which of the following is not a mode of working on the AI hackathon platform 

Microsoft Remote Desktop application on your PC to connect with a Virtual Machine 
PowerPoint Online to build a presentation 
Microsoft Teams running in a browser to communicate and collaborate 
Excel Online to work on files in your team area in Teams 
**Writing an essay about AI using Microsoft Word**

9. Which of the following 3 pieces of information will you receive to access the hackathon 

**Username** 
Form to fill in
**Password** 
**URL for Teams site** 
Quantum encryption codes

10. When you log into Teams is important that you use the Teams

Remote Desktop
**Web app – browser based**
Desktop app
Windows or Mac app
API

11. The two main crises covered by the AI for Earth program, and will focus of this hackathon are:  

Covid 19
**Climate change** 
**Biodiversity decline** 
Misinformation 
Cyber security

12. OceanMind uses satellites and artificial intelligence to help governments understand

Fish stocks
What fishing quotas should be
The effects of pollution on fish stocks 
The effects of global warming on fish stocks
**Illegal fishing** 

13. AI can help by enabling forestry managers to predict 

How many trees are needed for paper production
How much rain is likely to fall on their forests 
The effects of market prices for paper
**The outcomes of different forestry management techniques**  
How new machines can help cut down trees 

14. The ethical use of AI in agriculture can help farmers 

Breed more cattle 
**Make better sustainability decisions** 
Grow more soy
Select which parts of forestry to turn into cattle farms 
Grow more palm oil trees

15. Which of the following is not an example of where AI can help tackle climate change

Create new low-carbon materials that reduce the need for concrete and steel production
Better climate and extreme weather models
Optimised food supply chains and improved agricultural yields  
**Monitoring illegal fishing**
Improve manufacturing efficiency  

16. Which three of the following skills and attributes should an AI leader have 

**An appreciation of AI** 
**Tech savvy** 
Model building 
Data processing 
**Strategic & innovation mindset**
Programming 
Thought leadership 
System design and implementation

17. Which four of the following skills and attributes should a Data Scientists and Software Engineers have

**System design and implementation** 
**Data processing** 
Defining business problems
Thought leadership 
Managing change 
Data story telling
**Model building** 
**Programming**

18. In the Earth’s Energy Budget Python model, reducing both Emissivity, Albedo together

Increases ice cover
Cools the Earth
**Significantly increases the temperature of the Earth**
Enables more energy to flow into space
Has no effect on the Earth’s temperature

19. A key method for securing transactions electronically is to test for 

Hacking
Fraud 
Ciphers 
**Divisibility**
Encryption 

20. Decision trees have structures resembling 

Trees
**Flow charts** 
Forests 
Buildings
Neural Networks

## Technical Setup

A full set of technical setup instructions are provided in this video - https://vimeo.com/ 

You can also follow the written instructions below if you prefer. 

Click on the link to the hackathon Teams site that you received in your invite mail.  

Figure 22. You will receive an invitation email similar to this one 

containing the details you need to join the hackthon using Teams
This part is **very important**. 

Your username and password for this hackathon is temporary. You will not be able to use it after the hackathon.

Therefore, you need to use the Teams **web app**, not the default Windows or Mac app.
Please not install the Windows or Mac app on your computer. 

On your computer you will either have the teams App installed or not. 

If the Teams app is already installed, do not use it.  

Select “Use the web app instead”. 

Figure 23. Whether the Teams App is installed or not, you must use the Teams web app

Sign in with your given username, for example –

Figure 24. Sign-in part 1 - your username

Then enter the password And enter the password ‘H4ck1!0n’

Figure 25. Sign-in part 2 - your password

If you see this, you are IN! 

Figure 26. The 'General' channel and’ Posts’ function is where the entire hackathon group will meet

You can dismiss desktop notifications

### Testing 
You now need to test and become familiar with the capabilities of the platform for each of the 4 modes of work that you will be doing. 

#### 1. Teams
#### Home 
Click on ‘General’ immediately under the ‘Hackathon’ icon. 

‘General’, Figure 1, is the ‘home’ for the hackathon. 

‘General’ is a channel, and you will see that there are 7 channels in total. General is for everyone. The other 6 channels are for teams. 

Think of General as the ‘town hall’ where everyone can meet. Your tutors will meet everyone here, and you can use this forum to ask questions that you think everyone should know the answers to. 

This is also where messages about the hackathon and assignments will be posted. 

If you are lost or stuck, you should return here and ask for help. 

When it’s time for everyone to meet, you will see the notice show in Figure 6 below in the General channel. 

Your tutors will meet everyone here in line with the timetable. 

Figure 27. Notice to meet in the General channel

#### Class Notebook

Everything you need to know to complete the hackathon is in the Class Notebook in the General channel. All the information you need, and all the instructions for the tasks are detailed here. 

Start by clicking on the “Class Notebook” menu item in the General channel. 

Figure 28. Click on the Class Notebook to get all the information you need

Then click on the chevron 

Figure 29. Clicking on this chevron takes you inside the notebook

Open Content Library. Note – this may take a few minutes to open fully because there is a lot of content in the notebook. 

Figure 30. Clicking on the Hackathon Guide will take you to the information you need

Click the Hackathon Guide, and follow the hackathon steps using the notebook section headings

Figure 31. Work your way through the hackathon by clicking the titles in the middle column

Figure 32. Notebook section headings

#### Assignments 

Assignments will either be a quiz or a design challenge. 

When you need to do an assignment, a notice like the one in figure 12 below will appear in the General, Posts area. 

Figure 33. Assignment notification

When a notification appears, click on it to start work on the assignment. 

In the case of a quiz, for example, this will take you to a window like the one shown in figure 14 below. 

Figure 34. An example quiz assignment

#### Working With Your Team

Table 3 above, in the Identities And Groups section, will tell you which team you are working in. 

Click on your team channel and use the tools to communicate and collaborate. 

Figure 35. Click on your team's challenge to communicate and collaborate 

To **send a message** to all participants in a channel, first click on your channel and hit the New conversation button at the bottom of the screen.

Use the text box to draft your message. You can also attach files, emojis, GIFs, and more to the message before you hit send.

Figure 36. Messaging tools

To host a meeting -  

1. Go to your team channel and click on the Meet option in the top right. 

Figure 37. Connect with your teammates using the 'Meet' function

2. Invite others in your team to the call. 

3. Once you are in a call, you have the option to Screen share in the ribbon that appears on middle-bottom of the screen along with the Mute and Camera toggle options.

Figure 38. Screen sharing and other options are available at the bottom or the screen

#### 2. Practical Work - Excel Experiments
Some of the practical tasks will be in Excel. You will work with your teammates on 4 Excel files in your team channel. 

Figure 39. The Excel files you need to work on will be in your team’s channel in the ‘Files’ section. 

Test Excel Online by clicking on one of the files to open it in Teams

Figure 40. Work on the Excel files on your PC

Press ‘Close” to move on. 

#### 3. Python Practical Work
#### Introduction To Virtual Machines

Follow this video to understand how the virtual machine desktop and Visual Studio Code works - https://vimeo.com 

Working with Python involves using a ‘virtual machine’ that operates in the Cloud. Whilst you will see the machine on your computer, all the computation will take place far away from it. 

We need to do this because we need to use specialist libraries with Python which are easier to set up for all hackathon users on a virtual machine, than on everyone’s individual PCs. 

The virtual machine in the cloud is hosted in Azure Lab Services. The virtual machine’s operating system is a Windows Server. On top of Windows Server we run Visual Studio Code, which in turn runs Python. 

Microsoft Remote Desktop on your computer enables you to connect your PC with the virtual machine in the cloud. 

Figure 41. Your virtual machine will run in the cloud, but you will see and control it on your desktop

#### Azure Lab Services  

To access the virtual machine, you will need to navigate to General, Azure Lab Services. Then you will need to start your virtual machine, if it isn’t already running. 

Note that this may take 5 minutes to start.

Figure 42. Start your virtual machine before connecting to it

When the virtual machine is running, download the RDP file. 

Figure 43. When the virtual machine is running you can connect to it

Clicking on ‘Download RDP file’ will deliver an executable file onto your computer. 

Figure 44. An RDP file will download onto your computer

Press ‘escape’, go to the top of your screen, or press control-alt-break, and select 
- ‘Exit Full Screen’, and 
- ‘Fit to Window’ 

If it’s working correctly, you will see this, or an equivalent for Windows computers. 
 
Figure 45. Warning message that confirms that a connection to your virtual machine is happening

Click ‘Continue’, and you will be prompted to enter your password. 

Figure 46. Password challenge

Enter this password when prompted - **H4ck1!0n** 

When you have successfully connected, a virtual machine desktop will fill your screen. 

Figure 47. Your virtual machine desktop

Press ‘escape’, and select 
1.	‘Fit to Window’, and 
2.	‘Exit Full Screen’. 

Figure 48. Exit Full Screen and Fit to Window

Wait for all of the icons at the bottom of the screen to appear. 

Because this computer is in the Cloud, it will take time for commands run, so please be patient. 

#### Visual Studio Code

When the virtual machine is running, double click on the Visual Studio Code icon. 
 
Figure 49. Visual Studio Code icon

Wait for the full screens to fill with detail. 

Figure 50. Visual Code Studio in a working state

You will need to wait for the Python extensions to load. The status is in the bottom left of the Visual Studio Code screen. 

Figure 51. Python extensions status

When Visual Studio Code is running fully, you will be able to work with it. 

To run code, click on the green chevron here - 


Figure 52. The green chevron here runs the code in the open window

The terminal at the bottom of the Visual Studio Code window shows the outputs from executing an algorithm, so watch this carefully when you run the code

You will need to wait until the text in figure 33 below appears in the Terminal window. This could take up to 2 minutes. 

Figure 53. The text that you'll see in the terminal that shows that the code has executed correctly 

Ignore any popups about updates available. Just close using X.

This code also produces a graph. Note that graphs will appear behind the Visual Studio Code window so move the window to the side to reveal it.

Figure 54. The Visual Studio Code window with the output graph

#### 4. Build A PowerPoint Presentation 

The last part of the hackathon is a design challenge. For this you will need to build a pitch supported with a PowerPoint presentation.  
In your team area, click on ‘files’. 

Figure 55. Build a PowerPoint presentation in your team area, in the 'Files' section

## What Is AI?
### Capabilities And Applications 

AI is marching into our lives, affecting how we live, work and entertain ourselves. From voice-powered personal assistants like Siri and Alexa, to more underlying and fundamental technologies such as behavioural algorithms, suggestive searches and autonomously powered self-driving vehicles boasting powerful predictive capabilities. 

There are many examples of artificial intelligence in use today, including:

Figure 56. Examples of AI applications

These capabilities have a vast range of application areas, some good, some not so good, including: 
 
Figure 57. Examples of AI application areas

### Machine Learning

Let’s start unpicking AI by building a metaphor for it. Imagine that you are driving an AI enabled combine harvester.

As it cuts through the crop it applies AI – or **machine learning** (ML) to be more precise – capabilities.

The first thing it does is classifies the crop in terms of whether it is wheat or chaff. The wheat is separated into a tank and the chaff is blown out of the back of the combine harvester.

Next, it looks for anomalies – are there other species of plants in the crop?

Then it analyses the size of the grains, and clusters them into groups – something that could be useful when combined with geographic and soil analysis data.

Finally, it can forecast ahead. It can use regression analysis to predict the grain sizes and the overall yield.

Figure 58. A combine harvester as an analogy for AI and machine learning

Driving the Combine Harvester is a diesel engine which in turn drives an electrical generator, which powers its sensors, computing and communication capabilities.

We can think of AI as the Combine Harvester and the crop operating in the field, and machine learning as the engine that drives the ’intelligence’.

It’s really important to remember that **the point of machine learning is to make predictions**.

In the case of a combine harvester the outcomes could be a fully automated machine, real-time information to the markets, and information to form the basis of future crop planning.

To understand what AI is, we first need to understand how it is positioned against other related domains.

Figure 59. Where is AI?

Artificial Intelligence (AI) is a computer system able to perform tasks normally requiring human intelligence. Machine learning is a method for achieving AI.

Another way of looking at is to say that AI is a branch of ‘predictive analysis’ within the broader world of data.

Data is the basis of reasoning or calculation.

Big Data means large data sets that may be analysed to reveal patterns, trends, and associations.

Deep Learning is a form of machine learning based on neural networks that use many layers of processing to extract features from data.

In this hackathon we are going to focus on the ‘engine’ that drives AI – machine learning - which can be defined as a field in Computer Science that is focussed on enabling computers to learn.

Figure 60. We will be focussing on AI on this part of the course

### When Should Machine Learning be Used?

Presently, Machine Learning is complex and requires considerable resource to deploy, so we need to be clear about when to use it. 

Its most useful when we need to extract insights and make predictions from big data, multi-dimensional data, or data models with enormous numbers of permutations. 

It can also be useful when large volumes of constantly changing data needs to be analysed. 
 
Figure 61. When to use machine learning

### How Does Machine Learning Work? 

Whilst artificial intelligence can do some incredibly complex things, the basic machine learning process is very straight forward. 

First, we have some data - that data could be practically anything that can be captured in digital format. 

Next we apply an algorithm to that data - for example the algorithm shown here is a very simple piece of machine learning code written in Python. 

When we've applied the algorithm to the data, we then have something called a learned model. 

We can then input data for an unknown entity into the learned model - here for example we are looking to identify this animal from a learned model containing thousands of images of other animals. 

The learned model will then give us a prediction for what that unknown data represents. 

In essence all machine learning does is provide us with a prediction. By combining machine learning with other technologies we can build extremely sophisticated artificial intelligence solutions. For example in healthcare artificial intelligence can predict the probability of somebody having a specific disease; in driverless cars machine learning predicts the probability of collisions and informs robotic decision's to avoid them. 

Figure 62. How machine learning works

## Regression
### Predicting Water Consumption in Excel 

One of the most commonly used machine learning method is regression. 

Regression is a method for predicting values, and linear regression offers a very useful tool for making basic predictions.

A regression line is simply a line that best fits the data. 

Let’s suppose that we need to predict how much fresh water needs to be made available for a growing city. We have consumption data for the previous five years and we need to work out how much is likely to be consumed next year – i.e. in the sixth year.  

We will use thousands cubic kilometres – k km3 – as the water use unit. 

Water consumption has fluctuated in the last five years due to climate change but when it's plotted, we can see a general upward trend. 

We can use linear regression to make a prediction for how much water will be used next year. 
In the exercise that follows, we will run the simplest possible form of machine learning in Excel. Whilst running a simple regression analysis in Excel may not seem like its machine learning, in reality its taking training data, ‘learning’ from it and making predictions – which satisfies the requirements needed to be classed as machine learning. 

## TEAM PRACTICAL TASK 1

In your team channel, go to ‘Files’ and open ‘Linear regression.xlsx’ 

Figure 63. Open Linear regression.xlsx

This is a ‘time series’ chart with a regression line. 

The end of the line predicts what value y will be at x = 6. 

Change the numbers between B3:B7 to see how the line changes.

Figure 64. Making a prediction from data using a ‘time series’ plot

Here, we are using data to infer a trend, and make a prediction from it. To do this, we draw a line that fits the data we have. The goal of the algorithm is to draw a line as close as possible to all of the data points. 

Here, for example, the we can read the trend line to predict that consumption in year six will be 4.15 k km3.

Excel has a quick and easy way for filling in the missing value. 

Just highlight the data that you want to make the prediction from, then pull down the handle in the bottom right corner into the next cell. 

Figure 65. Making a prediction by extending a column of data

Try this for yourself. 

When you have finished, close the spreadsheet. 

Congratulations – you have just completed your first machine learning experiment! 

### Predicting Water Consumption in Python
 
Excel allows you to try out or explain simple machine learning concepts, but what happens when you have massive numbers of datapoints to process, or you want to incorporate the method into a larger software process or solution?  

Excel does not scale to process the large datasets we deal with in the real-world, and it lacks some key functionality of programming languages.

This is why using a General-Purpose Programming Language like Python makes sense in machine learning solutions, so let’s now explore how we can perform regression analysis in Python.   

Let's suppose now that we now want to predict water consumption for an area rather than a city, and we need to make that prediction as accurate as possible. 

As with the example that we used earlier, we want to predict water consumption next year, and our units of measurement are k km3.

### Data 

Because we want our prediction to be more accurate than our last, we will use data that goes back over 11 years to give us more data points. 

So this is the data we have, with x = a year, y = water consumed in k km3 - 
```
x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11]   
y = [11,12,25,21,31,40,48,55,54,60,61]  
``` 
And this – “?” - is the prediction that we want - 
```
x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11,12]   
y = [11,12,25,21,31,40,48,55,54,60,61, ?]  
```
Let’s now see how we can do this in Python.  

### Model  

Start your Azure Lab Services virtual machine as explained in “Technical Setup” section above.  

Figure 66. Start your virtual machine

### Explore the Algorithm 

Now follow this video to understand how to work with the linear regression algorithm in Visual Studio Code - https://vimeo.com 

Now open Visual Studio Code (VSC) and select Simple_predict.py 

Figure 67. Open 'simple_predict.py' in Visual Studio Code 

Click on the start button (green chevron) to run the code, and give it about a minute. Bear in mind that the plot may appear behind the VSC window. You should eventually get this 

Figure 68. Note both the detail in the Terminal and the plot

Let’s look at the code in more detail 
```
from pylab import *

x = [1,2,3,4,5,6,7,8,9,10,11]   
y = [11,12,25,21,31,40,48,55,54,60,61]   

scatter (x,y)

(m,c)=polyfit(x,y,1) 

print ("Slope(m),", m)

print ("y-intercept (c),", c)

yp=polyval([m,c],x) 

x2 = 12

y2 = m*x2 + c

print ("Predicted value of y in month 12,", y2)

plot(x2, y2, 'ro')

plot(x,yp)

grid (True)

xlabel('x')

ylabel('y')

show()
```
Figure 69. Polyfit linear regression algorithm code analysis

This may look complicated at first glance, but we can see how it works by breaking it down line by line. 

First, we import the pylab library, which does a lot of the calculation work for us. 

`from pylabimport *`

Add the data that we have
```
x = [1,2,3,4,5,6,7,8,9,10,11]   
y = [11,12,25,21,31,40,48,55,54,60,61]   
```

Define x and y as a scatter plot 

`scatter (x,y)`

Call the polyfit function to work out m and c for the standard equation for a linear regression slope, `"y = mx + c"`.

`(m,c)=polyfit(x,y,1)` 

Tell it what to print
```
print ("y-intercept (m),", m)
print ("Slope(c),", c)
```
Use 'polyval' to draw the line  

`yp=polyval([m,c],x)`

This gets us to this point – 
<!--- TODO: embed regressionline -->

Now we have our regression line defined, we need to set up two new variables – x2 and y2. 

We need to add one year to x, so x2 is now given as 12.

We calculate y2 by re-applying the slope formula - this time plugging in x2.
```
x2 = 12
y2 = m*x2 + c
```
The rest of the code handles plotting, laying out the graph, labelling the grid, and printing key data.

#### Prediction

The red dot in top right-hand shows predicted water consumption at year 12 at 71k km3.   

Figure 70. Linear regression prediction output

## TEAM PRACTICAL TASK 2
1. Close the current plot to terminate the program 
2. Change some of the ‘y’ values 

Figure 71. Change some of the 'y' values

3. Save the file 
4. Re-run the program 
5. Note the difference in the plot 

When you have done this you can close down VSC, close the Remote Desktop, and stop the virtual machine in Azure Lab Services. 

## EXTENSION TASK  
Correctly reorder the code in the document – “Linear Regression jumbled code.docx” 

## What Did We Learn? 
Regression, and linear regression in particular, is one of the most commonly used machine learning methods. 

Whilst we can easily run regression analysis in Excel. However, to use this in a web service, or to use much more data and more sophisticated modelling methods we need to write regression algorithms in a general-purpose programming language such as Python. 

Let’s now explore how AI solutions can be developed. 

## Machine Learning Applications 
 
So what can machine learning be used for?

Machine learning can be used for a vast array of applications, so let’s now get a flavour of the different types of uses that machine learning can be put to. 

### Natural Language Processing 

Natural Language Processing, or NLP, is the sub-field of AI that is focused on enabling computers to understand and process human languages. Computers doesn’t yet truly understand English in the way that humans do but they can already do a lot. 

Natural Language Processing is a top application of machine learning and use cases include: 
•	Voice recognition systems in smartphones  
•	Voice-controlled devices, such as the Amazon Echo 
•	Real-time language translation  
•	Sentiment analysis of text

Using machine learning, natural language processing (NLP) helps uncover insights and relationships in unstructured data. Emma, a chatbot at OCBC bank in Singapore, turns 10% of chats into loans. It uses Natural Language Processing and personality analysis, and the result is that customers feel “this interface understands me”. In its first eight months of operation it won $70m of home loan business. 

But how does NLP work. Take the following example text from which we want the computer to extract meaning – 

“London is the capital and most populous city of England and the United Kingdom. Standing on the River Thames in the south east of the island of Great Britain, London has been a major settlement for two millennia. It was founded by the Romans, who named it Londinium”.

<!--- numbering is off from here on -->
Figure 71. Natural language, text, on the left, and the code used to process it on the right

Running the code on the right-hand side of Figure 62 above, the output would be: 

Here is what I know about London:
- the capital and most populous city of England and the United Kingdom.
- a major settlement for two millennia.

Running the same code against a longer piece of text, such as the Wiki page for London, could yield a longer output if that was required. 

### Recommendation Engines 
Do you ever wondered why you keep on seeing adverts that relate to your interests? Putting adverts that are likely to be of interest to you is what recommendation engines do. 

The first step in creating a recommendation engine is gathering data such as purchases, ratings comments, return history, cart events, page views, click thru and search log.   

Since each user is bound to have different likes or dislikes about a product, their data sets will be distinct. Once the data is captured and prepared one of a number of recommendation machine learning models can be applied, including:   

**Content-based**: Recommends products with similar characteristics to what a user views or likes.
**Cluster**: Recommended products that go well together, no matter what other users have done.
**Collaborative**: Based on profiles of other users, who like the same products  

A collaborative based recommender is shown below: 
 
Figure 72. Simplified collaborative recommendation engine
Robots and RPA

AI, robots and automation technologies often get conflated because they are all linked with disruption of the jobs market. 

However, it’s important to draw a distinction between AI and robotics. 

- AI is not robotics
- AI is not automation
- But AI may be used in both

Computers don’t suffer from limitations that affect human beings. They’re not restricted by biology, they don’t get tired or ill, they can process information for long hours, and they’re exceptionally capable of doing repetitive and mathematical tasks.  

AI in itself is not the same as an automation process, but often AI and automation are used together. AI can use predictions to direct automation processes and use data fed-back from these processes to make more predictions in a virtuous cycle. The main automation tools used with AI are robots – both the physical and software varieties. 

Physical robots are the easiest to comprehend because we are used to seeing robots in factories and in the media. Software robots are functionally the same – they automate repetitive tasks – except that the moving parts in a software robot move information instead of physical objects.  

Robotic Process Automation (RPA), is about applying robotic principles to organisational processes. The typical cost of an RPA software agent compared to a person is about 1/3, so it’s clear that RPA is attractive to organisations.  

RPA works for scenarios with the following features: 
- Rules-based, predictable, replicable
- High volume and scalable
- Rely on multiple systems
- Where poor quality results in high risk or cost
 
Figure 73. Robots versus Robotic Process Automation

#### Autonomous Vehicles

Driverless vehicles are a form of robotics. Tesla, for example, has over 1.3 billion miles of training data for its driverless vehicles. 

Technically, autonomous vehicles are just robots designed for transportation, so many of the applications of AI found in robotics can be found in autonomous vehicles as well. 

AI vision systems enable vehicles to sense and identify the physical features and dynamics of their environment, from road lanes to pedestrians and traffic lights, with a high degree of accuracy. Combined with AI data processing and planning algorithms, AI is enabling the age of autonomous transport. 

### Image Processing
We will dive deeply into image processing later in the hackathon, but it’s worth briefly considering it here first. 

Machine learning is used in image processing in a wide range of scenarios – e.g. passport control, facial recognition in security scenarios, handwriting recognition, robot vision and driverless vehicles.

Images are data in the form of 2-dimensional matrices. If you feed enough labelled images into a classification algorithm, the learned model will be able to identify images with similar patterns in the matrix. 

Figure 74. Learning from images

## The AI Development Process 
 
Figure 75. Stages in developing AI solutions

### Define The Problem 

As with all technology projects the first thing that we have to do is define the problem that we want to solve. This involves writing a very clear problem statement. 

### Hypothesise 

The next step in the process is to build a theory about how to solve the problem. Ideally, this would include theories about what might deliver a good prediction, an alternative for delivering a good prediction, and what would not deliver a good prediction. 

### Prepare Data 

Often, preparing data for modelling takes the longest amount of time on a machine learning project. this is because data very often needs to be cleaned up and made consistent before it can be used effectively in a machine learning algorithm. 

Data for machine learning can come from a wide range of different sources and types. 

Figure 76. Data for machine learning systems comes in a variety of types and from a range of sources

The main goal is to put the data into matrices So patterns can be discovered using models. 
 
Figure 77. Data needs to be put into matrices to be processed

### Model Data

Whilst preparing data is perhaps the most time-consuming aspect of a machine learning project, selecting the right model can be the most complex part. 

To select the right model to work on the data you first need to define the kind of outcome that you want. 

Figure 78. A simplified model 'family tree'

This stage of the process involves taking training data, and learning from to produce a “learned model”. That learned model can then be embedded into an online service.  

### Deploy 

The final stage in the process is to deploy the model so that it can be used and constantly updated. If you use a service such as Uber, you are actually using an interface to Deployed AI model. All of the computing required to deliver the service happens in the Cloud, and your mobile phone act as a user interface into that service. 
 
Figure 79. Stages in AI solution deployment

Deployed AI solutions can take on a vast range of forms. 

Figure 80. An example of a deployed machine learning service - identifying animals in video streams

## Classification - The KNN Model 

Having explored regression, we can now turn to the other most commonly used type of machine learning model – classification. 

Classification models are used for predicting a category such as ‘married’, ‘single’, or ‘divorced’.

The method can be applied to an incredibly wide range of data – e.g. images, sounds, shapes, quality, size, accuracy, spam email.

Let’s dive right in with a machine learning classifier for different species of flower called the ‘Iris’. 

Figure 82. Using Excel to run a KNN classification model

1. In your team area, click on “Files”, and open “KNN in Excel.xlsx”
2. Follow this video https://vimeo.com 

Here we are going to demonstrate basic machine learning principles in Excel. The goal is to classify an unknown variety of Iris flower using its sepal length and width. 

As with every machine learning project we start with the data. Here we have three different species categorised by their sepal length and width. 

We can then put the length data on the X axis and the width data along the Y axis. We can then label this data. 

This labelled data can then be plotted. 

Next, we can bring in unknown flower and plot a position for it. 

We can see that it lies close to two known types of flower and we can perform a classification by finding out which of its neighbours is nearest to it. 

This method is called ‘K’ nearest neighbour (KNN) which is a commonly used machine learning classification method.

We use machine learning to work out the distances between the known flowers and the unknown flowers. 

To do this we use a formula called ‘Euclidean Distance’ which relates each data point to the unknown flower

Applying this formula gives us the distances from the unknown flower to the known flower. 

Now we have the distances between the unknown flower and each of the labelled flowers we can rank these in order of which known flowers are closest to the unknown flower. 

If you take the number of neighbours to the unknown flower to be 3, we can see that the three nearest neighbours are Virginica. 

If K = 4 then it gets a little less certain but it's still clear that there's a 75% probability that the unknown flower is Virginica. 

Finally we can plot our answer back onto the first plot that we made. 

## TEAM PRACTICAL TASK 3

You have 20 minutes for the task. If you complete the task with time to spare, we have provided you with an extension activity

Enter data for your own unknown variety of flower into the model and predict which of the three varieties it belongs to. 

Right click the ‘KNN (4)’ worksheet and holding the CRTL Key drag the tab to the right. This will create the new sheet ‘KNN (5)’ to work on.

Change the data that's given for the current unknown variety; note the label that is being predicted by the model; look back at the original plot in the ‘Plot’ tab, and see if your new prediction makes sense. 

Then experiment with different values for ‘unknown’. 

#### Extension Task 
Build a new worksheet with a new set of training data for two or three different classification categories.

Use the “=RANDBETWEEN(“ function in Excel to create random training data. 

Then enter new ‘unknown’ numbers, and make predictions without plotting them.

#### What Did We Learn? 
In this experiment, we took some labelled training data; applied an algorithm to that data; inputted some test data; and made a prediction about which category the test data belonged to. 

## SDG Exploration 1 Instructions 
Later today, we are going to discuss whether AI is good or not in the context of The United Nations Sustainable Development Goals. 

To prepare for this discussion You are being asked to undertake 2 tasks –

1. Explore interactive AI demos so you are familiar with what AI can do 
2. Research The United Nations Sustainable Development Goals, and think about how AI can be used to help achieve them. 

### Microsoft's Interactive AI Demos

Try these interactive AI demos - https://aidemos.microsoft.com 

In the Text Analytics service, analyse a variety of your own texts.

Figure 83. Microsoft's interactive AI demos

### UN SDGs + AI 

Explore each of these sustainable development goals and think about how AI can be used to achieve them. 
 
Figure 84. United Nations Sustainable Development Goals
https://www.undp.org/content/undp/en/home/sustainable-development-goals.html 

# DAY 1, PM
## Introduction to Trees 
 
We've already explored decision trees in the preparation for this hackathon, and we can now dive deeper into this area. 
 
Figure 85. A Decision tree
We can use machine learning to help us make decisions, and a key way of doing this is a decision tree.  

Decision tree models are the opposite of real trees because the root is at the top. Below the root are ‘decision nodes’ which branch out. Decision nodes contain pieces of data which the algorithm decides whether to select or not. Those decision nodes that contain the data that we are looking for are called ‘terminal nodes’. These terminal nodes contain - either a classification or a predicted number. 

Figure 86. In a decision tree, each layer reduces variance in data

The goal of a decision tree is to continually reduce variance in data to the point at which a subset of the data can either provide a classification or a predicted number. 

So what do we mean by variance in data? 

Figure 87. High (left) and Low (right) data

Variance is a measure of how spread out numbers are. 

Both of these charts above have data points with a mean of 25. However the chart on the right has lower variation in the distances between each data point and the mean.  

Data with low variance reveal patterns, and enable us to make predictions. 

As data flows through decision trees, variance decreases, and information is gained. 

There are several different ways in which variance in data can be measured, but a key method which we’ll look at here is called Standard Deviation (SD) - the square root of how far data points are from the mean. Another method is called ‘**Gini**’, and for the purposes of what we are learning here we can consider **Gini** as a proxy for SD. 

Decision trees work by dividing data into subsets that have increasingly lower Standard Deviation.
 
Figure 88. A tree of subsets with falling levels of Standard Deviation

Let’s now illustrate this with a practical example in Excel. 

Let's suppose that we need to make an investment decision related to wind farms.  

Specifically, we need to make a decision about which sector, project location (hemisphere), and project value, to invest in based on profitability. You can invest in as many projects as you like, but clearly you are going to want to invest in a very targeted way, so you need to find the kind of project is most likely to bring in the best return. 

Your data describes 50 projects that you could invest in. It has three features – sector, hemisphere and project value, and a label stating if the project described in the data is profitable yet or not. 

| | Sector | Hemisphere | Value | Profitable |
| --- | --- | --- | --- | --- |
| Example project data | Solar | South | Above $10m | yes |
| | Wind | North | Above $10m | yes |

To answer this, you can apply a decision tree algorithm to find the most profitable type of project. 

<!--- figure references are misaligned -->

Figure 73 below shows how the layers of the tree can be structured to give us the prediction we need. 

Figure 89. The decision tree structure

Figure 74 below Shows a possible route through the data that gives us an answer.

Here, for example, the tree is telling us that we should invest in solar in the northern hemisphere, and in projects that are valued at greater than $10,000,000 . 

Figure 90. A route through the data that takes us to a prediction

Let’s use Excel to show how this can be worked out. 

In your team area, go to ‘Files’ and open ‘Decision Tree.xlsx’ 

Figure 91. Open Decision Tree.xlsx

First, we need to be clear that we are using this decision tree as a classifier. Trees can also be used to provide regression analysis. 

Let’s start with the data.

We have 50 rows with 4 features in columns A, B, C and D. 

| Sector | Hemisphere | Value | Profitable |
| --- | --- | --- | --- |
| Solar | South | Above $10m | yes |
| Solar | South | Below $10m | no |
| ... |  |  |  |
| Wind | North | Below $10m | no |
| Wind | North | Above $10m | yes |

The goal is to find a category of investment that is, or is closest to, 100% profitable. 

In Excel, we can build the decision tree as a series of pivot tables. Click on each pivot table to see how they are built. 

Figure 92. The decision tree in Excel pivot tables
Note that the “Profitability” columns are added-on to the side of the pivot tables. 

This model tells us that the most profitable investment would be Northern Hemisphere, Wind, above $10m 
 
Figure 93. The 'terminal node' that gives us the category prediction we need is highlighted in red

## Decision Trees in Python	
### General Principles 

If we wanted to turn this into a web service, we would need to use Python rather than Excel, so let’s now see how this exact same analysis can be performed in Python. 

## TEAM PRACTICAL TASK 4
Follow this video to understand how the decision tree model on the virtual machine works - https://vimeo.com 

We have taken the data that was in the “Decision Trees.xlsx” worksheet and convert it into a ‘CSV’ file called ‘powergen.csv’. 

We apply our machine learning model to this data. 

Go to Azure Lab Services, open your virtual machine and run Visual Studio Code. 

First, look at the ‘powergen.csv’ data file to see what data is being used in the program. 

Figure 94. Powergen.csv data file shown in VSC

Next, close the powergen.csv tab. 
 
Figure 95. Close the data file tab by pressing 'X'

Open, explore and run 2_decision_tree.py

Figure 96. decision-tree.py Python code

Running the code gives us a plot. Maximise the window to see it more clearly:

Figure 97. Decision tree plot

Here, we can consider “gini” as a proxy for Standard Deviation. 

Let’s test for accuracy using random samples from the bottom set of nodes. For example, node 2 (2nd from the left on the bottom row) has 7 samples with values of 4 (non-profitable), and 3 (profitable). 
 
Figure 98. Node 2  

This matches the following pivot table on the spreadsheet – Wind, South, Above $10m. 
   
Figure 99. Same data, same prediction in Excel

Tracing this back to the root on the Python plot, figure 81 above, we see that it too is Above $10m (Below $10m, false), it’s in the South (South, true) and Wind (Wind, true).   

Our goal was to find the most profitable type of project. This is identified in a terminal node, and in this case the darkest blue node. 

Note that it has a Gini number of 0, which shows that the variance in the data is at its lowest point. This is because of 9 sample, 0 were non-profitable, and 9 were profitable. But note also that the terminal node on the far right also has a Gini number of 0. This is because all 6 of its samples are non-profitable. In both cases variance is at the lowest possible state, but it’s clear which one is profitable. 

  
Figure 100. The node on the left shows 9/9 samples were 'profitable'

So, if we trace terminal node 3 (3rd from the left) in Figure 81 to the root node we should be able to confirm that Above $10m (Above $10m = True), it’s in the North (South = False) and Wind (Wind = True).   

#### How Does A Python Decision Tree Work? 

Let’s explore the code 
```
from sklearn import tree
import matplotlib.pyplot as plt
import pandas as pd
	
seed = 1234
power_investment = pd.read_csv('powergen.csv')
y= power_investment[['Profitable']] 
X =  pd.get_dummies(power_investment[['Sector', 'Hemisphere', 'Value']])
	
clf = tree.DecisionTreeClassifier(max_depth=4, random_state=seed)
clf = clf.fit(X, y)
	
fig, ax = plt.subplots(figsize=(15, 10))
tree.plot_tree(clf, fontsize=12, filled = True, feature_names = list(X.columns))
plt.show()
```

**Lines 1-4** imports the libraries that we need. Libraries are pieces of code that run in the background when we run our program. The library that will build our decision tree is ‘sklearn’ from which we import the ‘tree’ function. 

**Lines 6-8** set out the variables. Line 6 reads the data from a data file. Lines 7- 8 set up the inputs into the tree model. 

**Lines 10-11** set out the parameters and fit the models components together. 

**Lines 13-15** plot the tree. 

**Your task** – 
Change the data source in the code from powergen.csv. to powergen_1.csv
Compare the output plot to the previous output as shown here in Figure 97, and: 
- Determine what was done to the data file to get the changed result
- Determine if the new result correct or not
- Explain how you know that this is correct or not

Model answer (explain in your own words)
- what was done to the data file to get the changed result  
    - The labels were inverted.  i.e. positives were flipped to negative and negatives to positive  
- determine if the new result correct or not 
    - It is correct
- explain how you know if it is correct or not 
    - As the labels are inverted, we would expect the model might remain the same but with the labels are similarly inverted.  By comparing the terminal nodes between the two plots, we can confirm that this is so.  E.g. the first terminal node contains values [2,1] indicating a prediction of 2 unprofitable and 1 profitable projects in the original plot and now contains values [1,2] meaning 1 unprofitable and 2 profitable projects.

#### Extension Task   
 
Correctly reorder the code in the document – 'Decision Tree jumbled code.docx' 

## A Day in the Life of an AI Practitioner 

Can you make a living from AI, and if so, what would it be like? 

Listen to learn-tech.io partner John Curry describe his work as a leading AI consultant. 

## Introduction To Forests 

Single decision trees are very useful, but chaining trees together can enable us to make more sophisticated kinds of predictions. 

A well-used machine learning model called Random Forest can give us both classification and regression predictions. 

A Random Forest is a collection of decision trees working together. We split the training data randomly into multiple sections and train a new decision tree on each data section separately. We then apply our test data to each decision tree separately. Each data point will be categorised by each decision tree. The model then brings these together, as an ‘ensemble’, and averages the probability scores for each category. We run multiple iterations and end up with a set of category probabilities for each feature. 

Let’s explore a use case for Random Forest by thinking about real forests. 

Every 6 seconds an area of forest the size of a football field is destroyed, and fire is a main cause. 

Figure 101. Tree loss

Let’s say that we wanted to be able to predict if an area of rainforest is likely to succumb to wildfire so we can prevent it happening. 

To make a prediction we first need some data. 

Ideally, we’d have data that would allow us to assess a piece of forestry in terms of its wildfire risk factors.

In order to illustrate how predictions can be made well use some fictitious data based on the following risk factors: 

**Fuel** – combinations of grass, trees and dense brush burns ferociously 
**Slopes** – steeper slopes can increase the speed and intensity of wildfire
**No Access** – dead-end roads can impede fire-fighting equipment
**Slash & Burn** - farmers, and miners deliberately destroying forestry 
**Drought** - makes fuel dryer and more prone to catching fire

Imagine that we then build a database of 100 monitored forests from around the world covering the past year. The database shows 50 fires, and states what factors were present in each case - expressed as a 0, not present, and 1, present.    

We’ve collected this data in a CSV file called ‘forestation.csv’. 

This is our data - 

Figure 102. Risk factors versus fires occurring in observed forestry over 1 year
From this data we want to know two things – 

1.	Which of these risk factors have the biggest influence on wildfires happening? 
2.	Given a set of known conditions for a given piece of forestry, what is the probability of a fire happening in the next year, assuming similar conditions 

Random Forest allows us to make both these predictions. We can use the same data in two separate Random Forest algorithms - 

Figure 103. The same data can be used by different random forest algorithms to make different types of predictions

## TEAM PRACTICAL TASK 5

Follow this video to understand how to work with the random forest algorithms in Visual Studio Code - https://vimeo.com 

Open Visual Code Studio on the virtual machine and run ‘3_random_forest_influential_factors.py’

Wait! 

After a short while you will get an output which ranks the fire risk factors in order of significance -

Figure 104. Plot output ranking influential factors
Close the plot. 

Now run ‘4_random_forest_predict.py’. Here, we’ve set the risk factors to the following - 
```
Fuel = 0
Slopes = 0
Access = 0
SB = 0
Drought = 1
```
1 = present, 0 = not present. 

When we run this, we get a different type of output – just two numbers in the TERMINAL:
```
Accuracy:  0.85
[0]
```

This result shows that based on the data, drought on its own was not enough in the past year to lead to a fire, and therefore we can predict that in the next year the same would be true. The accuracy of this prediction is 85%.

This then leads us to a question about what combinations of factors would lead to the risk threshold being 1. 

Change the risk factors to explore different combinations and their impact on the risk, and note what combinations lead to a [1]. 

Now change the data source in both programs to ‘forestation_1.csv’ and note the differences in outcomes from using ‘forestation.csv’. 

## TEAM PRACTICAL TASK 6
Open ‘3_random_forest_influential_factors.py’ change the data source to ‘forestation_1.csv’. Save the file and run it again. Compare and explain the difference between this and the previous results. 

Repeat this for ‘4_random_forest_predict.py’. 

### Extension Task  
Follow the explanation of the code below and then correctly re-order "Random Forest jumbled code.docx"  

### How does a Python Random Forest program work? 
Let’s now look at each algorithm in turn starting with ‘3_random_forest_influential_factors.py’
```
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.metrics import accuracy_score
import os
os.chdir("data")
	
seed = 1234
forestation= pd.read_csv('forestation_1.csv')
forestation
	
y= forestation[['Fire']] # predicting fire
categoricals =  pd.get_dummies(forestation[['Fuel', 'Slopes', 'Access','SB','Drought']])
	
X = pd.concat([categoricals], axis = 1)
	
clf = RandomForestClassifier(random_state=seed)
clf = clf.fit(X, y.values.ravel())
	
y_pred = clf.predict(X)
	
def plot_feature_importance(importance,names,model_type):
	
    feature_importance = np.array(importance)
    feature_names = np.array(names)
	
    data={'feature_names':feature_names,'feature_importance':feature_importance}
    fi_df = pd.DataFrame(data)
	
    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)
	
    plt.figure(figsize=(10,8))
    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])
    plt.title(model_type + 'FEATURE IMPORTANCE')
    plt.xlabel('FEATURE IMPORTANCE')
    plt.ylabel('FEATURE NAMES')
	
plot_feature_importance(clf.feature_importances_,X.columns,'RANDOM FOREST ')
plt.show()
```

**Lines 1 - 9** call libraries that run in the background

**Lines 11 – 23** defines variables and functions 

**Lines 25 - 33** is where the data is organised, the calculations are performed, and the output data is sorted. 

**Lines 35 - 42** handles the plotting. 

Let’s now look at ‘4_random_forest_predict.py’

```
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.metrics import accuracy_score
import os
os.chdir("data")
	
seed = 1234
forestation= pd.read_csv('forestation.csv')
forestation
	
y = forestation[['Fire']] # predicting Risk
categoricals =  pd.get_dummies(forestation[['Fuel', 'Slopes', 'Access','SB','Drought']])#get dummies for categoricals
	
X = pd.concat([categoricals], axis = 1)
	
clf = RandomForestClassifier(random_state=seed, max_depth = 5) # maximum depth of 3, use seed for repeatability
clf = clf.fit(X, y.values.ravel())# fit a model
	
y_pred = clf.predict(X)
accuracy = accuracy_score(y, y_pred, normalize=True)
	
Fuel = 0
Slopes = 0
Access = 0
SB = 0
Drought = 1
	
print ('Accuracy: ', accuracy)
print(clf.predict([[Fuel,Slopes,Access,SB,Drought]]))
```
**Lines 1 – 23** are the same as for 3_random_forest_influential_factors.py’

**Line 24** adds an accuracy score 

**Lines 26 – 30** are inputs for the fire risk factors  

**Lines 32 - 33** prints the results in the TERMINAL.  

## DG Exploration 2 Instructions 
### How Many Trees Do We Need to Plant? 
As plants and trees grow, they take carbon dioxide from the atmosphere and turn it into sugars through photosynthesis. Young trees absorb CO2 at a rate of around 6kg per tree each year. Trees reach their most productive stage of carbon storage at about 10 years at which point they are estimated to absorb around 22kg of CO2 per year. 

The Intergovernmental Panel on Climate Change (IPCC) said that if the world wanted to limit the rise to 1.5C by 2050, an extra 1bn hectares (2.4bn acres) of trees would be needed. 

Figure 105. A space the size of USA needs to be planted with trees to capture 2/3 of CO2 emissions. The space is available though.

Recent research from Crowther Lab  suggests that there is room for an extra 0.9 billion hectares of additional tree cover, excluding existing trees and agricultural and urban areas. 
 
Figure 106. Global analysis of tree cover showing potential for increasing cover in areas that are already wooded.

The researchers built a model for analysing existing tree cover, and categorised land use scenarios by the numbers of existing trees per hectare. The model was then used to predict how many more trees could be planted across the world and concluded that the main opportunities were in Russia, USA, Canada, Australia, Brazil and China . 

### Your Task   

Research and answer the following questions -  
1.	How could you use AI to work out how many trees you can plant in your country?  
2.	How could you work out which are the best places to plant more trees? 
3.	What are the practical things you would need to do this?

## Checkpoint 2 

1. Artificial Intelligence is 

A method for achieving AI
Large data sets that may be analysed to reveal patterns, trends, and associations
The basis of reasoning or calculation
**A computer system able to perform tasks normally requiring human intelligence**
A form of machine learning based on neural networks  

2. Machine learning is

A computer system able to perform tasks normally requiring human intelligence
Large data sets that may be analysed to reveal patterns, trends, and associations
**A method for achieving AI**
The basis of reasoning or calculation
A form of machine learning based on neural networks  

3. Data is 
Large data sets that may be analysed to reveal patterns, trends, and associations
A form of machine learning based on neural networks  
A method for achieving AI
A computer system able to perform tasks normally requiring human intelligence 
**The basis of reasoning or calculation**

4. Big Data is
The basis of reasoning or calculation
**Large data sets that may be analysed to reveal patterns, trends, and associations**
A method for achieving AI
A computer system able to perform tasks normally requiring human intelligence
A form of machine learning based on neural networks  

5. Deep Learning is 

A computer system able to perform tasks normally requiring human intelligence 
A method for achieving AI
The basis of reasoning or calculation
Large data sets that may be analysed to reveal patterns, trends, and associations 
**A form of machine learning based on neural networks** 

6. The point of machine learning is to 

Process language
**Make predictions**
Learn from training data
Classify data
Find patterns in data

7. What is the correct order for the Machine Learning process 

Input > Algorithm > Prediction > Data > Learned model 
Algorithm > Learned model > Prediction > Data > Input 
Input > Algorithm > Prediction > Learned model > Data 
**Data > Algorithm > Learned model > Input > Prediction** 
Learned model >Input > Prediction > Data > Algorithm 

8. KNN is 

Kelvin Nuclear Neutron, a classification method
Klystron Nucleotides Nebula, a regression method
Kaleidoscope Neural Nephrology, a classification method
Kaleidophone Neurology Nucleus, a regression method
**K Nearest Neighbour, a classification method**

9. What is the correct order for the Machine Learning process 

Define Problem > Deploy > Hypothesise > Prepare Data > Model Data  
Prepare Data > Model Data > Deploy > Define Problem > Hypothesise  
Deploy > Model Data > Prepare Data > Hypothesise > Define Problem  
**Define Problem > Hypothesise > Prepare Data > Model Data > Deploy**
Hypothesise > Define Problem > Deploy > Model Data >Prepare Data  

10. Which of the following is not a Machine Learning application 

Recommendation engines
Natural language processing
Robotics and RPA
**Big data**
Image processing

11. Which of the following is not use case for natural language processing 

**Facial recognition**
Real-time language translation  
Sentiment analysis of text
Voice recognition systems in smartphones  
Voice-controlled devices

12. Collaborative recommendation engines

Recommend products that go well together, no matter what other users have done
Are based on profiles of other users, who like the same products  
Recommend products to users based on price
**Recommend products with similar characteristics to what a user views or likes** 
Are based on profiles of other users who are not interested in the same things

13. AI is 

The same as robotics
Can be used in robotics but not in automation
Is the same as automation
Can be used in automation but not in robotics
**May be used in both robotics and automation**

14. Which of the following is not use case for image processing

**Voice controlled devices**
Handwriting recognition
Robot vision
Driverless vehicles
Facial recognition

15. In a Time Series  

**Time is plotted along the ‘x’ axis and a variable is plotted on the ‘y’ axis**
Three axes are used – x, y and z
A variable is plotted along the ‘x’ axis and time is plotted on the ‘y’ axis
Time is plotted along both the ‘x’ axis and ‘y’ axis
Variables are plotted along both the ‘x’ axis and ‘y’ axis 

16. In the Python linear regression code analysis, we learned that the ‘Polyfit’ function’s job was to work out 

The value of y in month 12
Draw the line 
**m and c for “y = mx + c”**
x2
How much water was used in year 11

17. In the Python linear regression code analysis, we learned that the ‘Polyval’ function’s job was to work out 

The value of y in month 12
**Where to draw the line** 
y2
x2
How much water was used in year 11

18. In a Decision Tree 

A terminal leaf contains either a classification or a predicted number
A node contains either a classification or a predicted number
**A terminal node contains either a classification or a predicted number**
A leaf contains either a classification or a predicted number
A node contains an algorithm

19. A Random Forest is

Part of a Neural Network
Needs less data than other machine learning methods
The same as Natural Language Processing
Used to predict where wildfires will occur
**A collection of Decision Trees that work together to make a prediction**

20. Crowther Lab recently used machine learning to predict that there is room for an extra __________ hectares of additional tree cover on the planet. 

0.9 million  
**0.9 billion** 
0.9 trillion  
0.9 quadrillion
0.9	quintillion

# DAY 2, AM

## Image Classification Introduction
 
Machine learning is used to classify images across a wide range of scenarios – e.g. facial recognition at passport control, handwriting recognition, driverless vehicles, and recognition of living things. 

Figure 107. Image categorisation algorithms extract features to make predictions

An analysis of the principles of machine learning that are applied to image processing can reveal more general machine learning principles that can be applied in other scenarios such as voice recognition, for example.

### How Does Image Classification Work?

Let’s now turn to a practical application of image classification. 

Imagine that you are a data scientist working in an organisation that has been commissioned to find the best places on Earth to plant more trees. You have access to satellite imaging and can search through millions of images of aerial views of land. 

Figure 108. A satellite observing the Earth. Image source NASA.
Your goal as a data scientist is to find the right data, prepare that data, and build an experiment that identifies land that can be used for planting trees.  

From the satellite data we have a series of images that can be categorised and ranked by their tree growing potential. 

Our goal is to be able to classify a test image of area and get its tree growing potential rank. 
 
Figure 109. Our goal is to categorise tree growing potential of a piece of land

The image recognition problem we are working on here is very similar to KNN task that we worked through. The goal is the same – a classification. The method is the same – we categorise a piece of test data in terms of how well it fits categories labelled in the training data. The main difference is that the KNN model worked with just sets of two numbers representing x and y values stored in a CSV file. Here the numbers are patterns stored in the images. 

To illustrate the principles of image categorisation, we are going to run an experiment which uses just 10 images as training data. 

This is enough for us to demonstrate the principle, but clearly if we were doing this as an operational web service, we would use thousands of images.

Each image is labelled 0-9 in rank order of its additional tree growing potential. 

 
Figure 110. The training data

Here, 0.png – 9.png are the 10 **training** data images that we’ll use. 

We have another set of images that we need to rank. 

 
Figure 111. The test data

Here t0.png – t9.png are the **test** data images, and we’ll use these one at a time.  

Our goal is to match the test data images to a training data image. To do this we rename one of the test images to 10.png. 

Figure 112. Rename one image from the test images

We could have picked any of the test images here, but we chose ‘t0.png’. 

## TEAM PRACTICAL TASK 7

Learn how an image classifier works. 

First, follow this video - https://vimeo.com 

Then follow the text below - 

Let’s use Visual Studio Code to categorise our test images. 
Open your virtual machine, and VSC. 

Click on ‘data’, and ‘images_part1’

This is how the data looks in VSC – 

Figure 113. How the data looks in Visual Studio Code

0.png – 9.png are the training images

10.png and t1.png – 9.png are the test images. Note, we have renamed t0.png to 10.png.  

10.png is the test image that we need to find a category match for. 

Now we have our data organised, we can next run the code. 
 
Run ‘5_image_recogniser.py’ 

Figure 114. ‘5_image_recogniser.py’ code
 
Figure 115. ‘5_image_recogniser.py’ code running

Note that it shows a greyscale version of the test image ‘0.png’. 

This means that it has found a match for our test file.

Figure 116. The algorithm matches the test image file to a training image file
The test file 10.png matches the training file 0.png. 

Once we have a match, we can assign a classification. Here, we find that the piece of land in our test file has only 10% additional tree growing capacity. 
 
Figure 117. Types of land classified and ranked according to their additional tree growing capacity

To find a test file that shows land with higher levels of tree growing capacity, we follow these steps: 

- First, we rename 10.png back to t0.png
- Next, we pick another image file, say t8.png and rename that to 10.png 
- Then we run the classifier ‘5_image_recogniser.py’

Here we see that the new test image 10.png matches the training image file 8.png which has been classified as having 90% extra tree growing capacity. 

Figure 118. Our test file has been matched to a training file which in turn has been classified, so we can now classify our test file

**Try this for yourself** - 
1. Rename 10.png to t0.png
2. Renaming any of the training images to 10.png 
3. Run the classifier  
4. Determine the additional tree growing potential 

### How Does The Classifier Work?

Before we progress to the next task, we need to understand how the model works. 
The first thing to understand about image classification is that digital images are simply numbers. 

An essential idea here is that images can be represented digitally. Once we have an image represented by numbers in an array, we can apply machine learning algorithms to them.

The code in 5_image_recogniser.py first imports two libraries; then reads the image file; then prints the results – a set of arrays describing its colours and composition. 
```
from scipy import misc
import numpy as np

A = misc.imread('1.png')

print(A)
```

Figure 119. arrays describing images’ colours and composition

Once we have this data, we can reverse the process and create an image from the numbers. 

If we ‘flatten’ the image from colour (RGB) to greyscale it results in far less data being generated
``` 
from scipy import misc
import numpy as np

A = misc.imread('1.png', flatten=True)

print(A)
```
Output - 

Figure 120. Arrays for images after ‘flattening’ to greyscale

Once we have the image described in numbers, we can find best numerical matches – classification. 

To do this the code follows a three-step process – 

First, it reads and converts both the training images and the test image to greyscale
 
Figure 121. Flattening training data images

Next it applies a method called “Singular Value Decomposition (SVD)” to each image. This extracts patterns from the greyscale arrays. 
 
Figure 122. Extracting patterns with SVD

Next, the algorithm searches through the SVD values for the training data to find the best match between the training images’ SVDs and the test image’s SVD. 

Figure 123. How the classifier algorithm matches the test data to its closest fit training data image

Let’s now look at 5_image_recogniser.py in full -  
```
import scipy
import numpy as np
import matplotlib.pyplot as plt
from sklearn.externals._pilutil import imread

traindigits = []
for i in range(11):
    A = misc.imread(str(i) + '.png', flatten=True)
    B, c, D = np.linalg.svd(A, full_matrices=False) 
    traindigits.append({'original': A, 'singular': c[:10]})  

testdig = traindigits[10]  

recogniseddigit = min(traindigits[:10], key=lambda e: sum((e['singular']-testdig['singular'])**2))

plt.imshow(recogniseddigit['original'], interpolation='nearest', cmap=plt.cm.Greys_r)
plt.show()
```
The loop starting with **line 6** `traindigits = []` takes the images, ‘flattens’ them to greyscale arrays, then applies the SVD algorithm to each array. 

**Line 12** `testdig = traindigits[10]` sets a variable for the test image. 

In **line 14**, `recogniseddigit = min(..` looks for the training data SVD that has the lowest difference between itself and the test digit SVD. 

In **lines 17-19** we show the test data image file that corresponds to the test data array with the lowest difference.

It's critical to note that a commercial application of image recognition would use much more training data than we have done here. For example, each of the digits below may have been inputted as hundreds, thousands or even millions of different images. In addition, the algorithm would be much more complex – for example, adding a decision tree to this code would greatly increase data.

## Image Classification Task
## TEAM PRACTICAL TASK 8
Follow this video to understand the task - https://vimeo.com 

Your objective: Identify where best to plant trees in populated areas. 

Figure 124. Finding the best places to plant trees in a populated area using image analysis

You will have 5 resources to work with

1. Training images
2. Test images 
3. Model testing code 
4. Jumbled-up code 
5. ‘Starter’ spreadsheet  

Figure 125. The assets that you will need for the task

#### 1. Explore the Data and Algorithm  
First let’s explore the data. 

On your virtual machine, go to the file icon at the bottom of the desktop, and navigate to C:, hackathon, data, and images_part2. 

As in the previous example, we have some training images and some test images. This time the images are from populated areas. 

Next open VSC, and 6_image_recogniser_2.py 

Arrange the windows so you can see both the data and the algorithm together. 

Note that the algorithm here is the same as the one that we used previously – 5_image_recogniser_2.py. The only difference is that we have changed the parameters to use more data image files. 

Next choose a test image to rename – t1, for example. This time we rename the test image to ‘21’. 

Now run 6_image_recogniser_2.py and wait for the program to display the best matched image from the training data.  

After a short wait, an image of aircraft at an airport should appear. 

Looking at the training images we can quickly see that we have a good match. 

Making sure that we change ‘21’ back to its original ‘t’ number, we can repeat this process to further test that it works. 

Finally, change the last ‘21’ back to its original ‘t’ number. 

#### Rank Land-Use Categories

Your next task is to rank each category of land-use by how many additional trees could potentially be planted. 

Look carefully at the images in the ‘images_part2’ folder and use the table below to match the images to the labels.  

Table 4. Training images category labels

In your team’s File area, use the Excel file called ‘Test table.xlsx’ to rank each category of land use in terms of how many additional trees you think could be planted. 

Think carefully how about the criteria. For example, is it safe to plant trees next to a runway, or is it practical to plant trees in a harbour? On the other hand, it could be relatively easy to plant many more trees in areas such as golf courses and on riverbanks. 

Below are two example rankings – try and put your own ranking in here. Don’t spend longer than 10 minutes on this part of the task. 

Figure 126. In Excel, rank each category of land by its tree growing potential

#### 2. Write the Code 
Now open 7_image_recogniser_2_jumbled.py

You will need to do two things – 

#### 1. Put the lines of code in the right order. 
```
plt.imshow(recognisedimage['original'], interpolation='nearest', cmap=plt.cm.Greys_r)

plt.show()

recognisedimage = min(trainimages[:x], key=lambda e: sum((e['singular']-testimage['singular'])**2))

from scipy import misc

trainimages = []

for i in range(x):

    A = misc.imread(str(i) + '.png', flatten=True)

    B, c, D = np.linalg.svd(A, full_matrices=False) 

    trainimages.append({'original': A, 'singular': c[:x]})  

import numpy as np

import matplotlib.pyplot as plt

testimage = trainimages[x]  

import os
os.chdir('data/images_part1')
```

#### 2. Change the parameters 
The code above is the same as 5_image_recogniser.py except that we have replaced some parameters with ‘x’. You will need to replace the ‘x’ with the right number. 

- Note that one parameter is based on the total number of images  
- Two parameters tell the algorithm to read the training images 0.png to 10.png 
- One parameter specifies the number in the name of the test image  

Count the number of images, and adjust the four parameters accordingly. 

When your algorithm is ready, imagine that you have been given the task of working out the best places to plant more trees in your area. You have collected a series of satellite images – t0.tif – t20.tif. Now you need to establish what the tree growing potential is for a minimum of 5 of these images. 

To do this, we’ll follow the same steps as we did in the video - https://vimeo.com 

For example, take the image named t10.tif. Rename this to 10.tif and run the algorithm. You should get an output showing a greyscale representation of one of the training images – in this case, 10.tif. 
 
Figure 127. Matching training image to the test image 

Look up 10.tif in your table, and state its corresponding name (Harbor) and tree growing potential, say 0%, into a new column.  

Repeat this so you have at least 5 images analysed. 

Figure 128. Complete the table with test results to find the test image with the most tree growing potential

Data source acknowledgement - Yi Yang and Shawn Newsam, "Bag-Of-Visual-Words and Spatial Extensions for Land-Use Classification," ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM GIS), 2010.

## Neural Networks 

Neural networks are modelled on how the brain works at its most basic level. Thinking is a product of electro chemical activity. Thoughts, or more precisely ‘cognition’, occurs in ‘synapses’. A synapse is formed when two or more neurons are connected electrically. At the most basic level, a neuron makes a decision, and that decision depends on weighted influences.

Whilst electronic computers can perform individual calculations faster, the human brain is many times more powerful than even the fastest computers because it processes more information in parallel. The vast numbers of potential connections between neurons in the brain means that we are capable of more thoughts than the number of atoms in the universe. 
 
Figure 129. Neural networks are modelled on how the brain works
So how does this relate to AI? 

Cutting edge AI uses neural networks which attempt to mimic how cognitive processes work. 

Imagine you were considering whether to buy something or not. Two people told you ‘yes’, you should buy it, one person said ‘no, don’t buy it’. Chances are you’d go with the two “yes” answers.

A neuron works in a similar way. If it receives enough stimulus, a connect in is made, and that connection is called a synapse. We can mimic this with software, and doing so unleashes enormous machine learning capabilities.  

If we treat an output from a synaptic process in the in the same way as we treat an output in machine learning – i.e. as a prediction – then we have a new basis for making predictions. 

The basic building block of a neural network is the perceptron, which mimics a synaptic process.

Figure 130. A Perceptron

We can mimic the synapse with software using a model that places ‘weights’ in ‘nodes’, and using the outputs of nodes - ‘bias’ - as a signal to another node. Together the use of weights in nodes and biases mimic neural networks in the brain, hence the use of the term “neural networks” in machine learning. 

It’s important at this point to understand that the neural networks that we are discussing here exists in software. They are virtual – in other words, there isn’t a physical circuit as such, but defining the nodes and layers in this way provides a blueprint for the software. 

The reason neural networks are so powerful is because of the extent to which connections can be made. We can chain nodes together in layers. The more layers, the deeper the learning. Millions of nodes arranged in layers, can make billions of connections, and each connection can use different weighs; which in turn opens up an almost infinite number of permutations.

Neural networks come in an infinite variety, but generally they operate by passing input data through layers of nodes where they are weighted in various combinations, summed, and passed on to the next layer. This combination of simple calculations results in the ability to learn sophisticated class boundaries and identify complex patterns. 

Neural networks are particularly suited to unsupervised learning tasks, such as object recognition from images or feature extraction from speech. 

High performance doesn't come for free - neural networks can take a long time to train, particularly for large data sets with lots of features. They also have more parameters than most machine learning algorithms. 

## Neural Networks Applied to a Problem 
Let’s look at how a neural network could be used to classify food ingredients as unhealthy or otherwise. You will see that it is based on labels, features and vectors.

Here we are using labelled data, so it’s a supervised learning scenario. 
 
Figure 131. Binary classification problem for a neural network
Can you work out the rule, algorithm and how Ingredient ‘x’ should be categorised? 

Ans – The rule is that any ingredient with fat or salt is given a vector of 0

Ingredient ’x’ has fat, so a vector of 0, therefore it is categorised as unhealthy. The algorithm is “If vector = 0, then ingredient = unhealthy”. 

A neural network takes training data and learns the rules. These rules are then encoded into ‘weights’. Weights are expressed as an algorithm in neuron, or node. 

Let’s look at how a neural network approach could handle a challenging categorisation. Take the example of an Avocado. Avocados contain fat, as well as vitamins and fibre. So now the classification is a little harder.

The layers below show the training data as an input layer, a set of algorithms that perform calculations in the middle (‘hidden’) layer, then an output layer which gives us a prediction or answer.  

The rule that the neural network has learned from the training data is that to be classed as ’healthy’, bad features (salt and fat) must be outnumbered by good features.

These rules are expressed as 4 simple equations, which are called the weights. The weights are contained in a ‘node’. 

Figure 132. Structure of the basic neural network

##Expanding a Neural Network’s Layers and Nodes 
 
In the example above we processed just one piece of data – an ingredient. But what happens if we want to process many pieces of data simultaneously? 

The beauty of neural networks is that they can take many inputs at the same time. 

In the example below, we will explore what it takes to be a ‘ZEP’. A ZEP is a Zero Emissions Person – someone who has the lowest possible personal carbon footprint. The goal of our neural network is to classify someone as a ZEP or not depending on their personal carbon footprint. 

This example follows the same pattern as the previous example, but we’ll expand the number nodes and layers to show how more sophisticated networks can be built. 

Here, we’ll focus on the testing rather the learning aspects and accept that the weights in the nodes had been trained previously. 

We start with a table with a set of categories – Transportation – Support climate action. These categories are chunked into threes – clusters 1 – 3. Each category has 3 sub-categories. Points are awarded for attributes.  The points awarded are fed into Layer 1 of the neural network – the input layer. 

If, for example, someone cycles or walks most days, they get 2 points and the two points are passed into the input layer. 

Each category has a corresponding node in Layer 2 where the scores from the input layer are added. 

The nodes in Layer 2 send a ‘bias’ to Layer 3 which adds the sum of the bias’. It then takes this sum and applies logic to it – if the sum is greater than ‘x’ then the output will say “ZEP” or “non-ZEP”. 

Figure 133. Layers in the neural network

## Build a Neural Network in Excel
## TEAM PRACTICAL TASK 9

Let’s now build a neural network. We’ll do this in Excel. Clearly, Excel is not something we would use to build an online service with, but it allows us to understand the principles of neural networks. 

The diagram below is the implementation of the diagram above, with the following differences – 

- Remove the first column – it’s not needed for the calculation. 
- Layer 1 has the following weight (formulae) – `=SUM(D2:D4)`, repeated for each of the 9 categories. 
- Layer 2 has the following weight – `=SUM(E2+E5+E8)`, repeated for each of the 3 clusters of categories. 
- The Output Layer has the following weight – `=SUM(F2+F11+F20)`.
- Add-in a “Threshold”. 
- Apply conditional formatting to Output Layer cell – 

Figure 134. Conditional formatting
 
Figure 135. The neural network in Excel

That’s it! A working neural network in Excel. 

Your task now is to ‘reverse engineer’ the Neural Network in Excel file ‘Expt Neural Network Excel.xlsx’ in your team File area in Teams. 

Next, open the “Experiment” tab to build your own neural network. 

Figure 136. Build your own neural network

First, think of a UN SDG goal, and then think of a scenario within that goal. Set up your criterial for that scenario in the same way as we did in the “ZEP” illustration. 

It’s important that you don’t spend more than 5 mins to think about the scenario, and if you get stuck, then just produce your own version of the “ZEP” example. 

You can also reduce the number of categories if it makes sense to do so. 

## SDG Exploration 3 Instructions 
### Endangered Species - Can AI Help?

According to a United Nations report issued earlier this year to policymakers, one million species, out of the 8.7 million species on the planet, are at risk of extinction: Human actions threaten more plants and animals than ever before.

Figure 137. AI can help track endangered species

A key problem for conservationists is that it’s difficult to track and monitor populations of endangered species. However, collecting better data and analysing it more effectively with machine learning and AI allows conservationists to make more targeted and timely interventions.  

Read and follow the links in this article to get an understanding of how AI can help. 
https://news.microsoft.com/on-the-issues/2019/08/06/ai-endangered-species/

When you have explored this article, think carefully about how AI can be applied to preserving smaller species. For example, bees and other pollinating insects are in sharp decline and without them food production becomes more difficult because much of the food we eat comes from plants that need to be pollinated. Can AI help the decline of bees or other insects that play vital roles in our food chain? 

# DAY 2, PM
## TEAM PRACTICAL TASK 10 
### Design Challenge Brief
The design challenge is where you get to put all that you have learned into action by building a pitch. 

A pitch is essentially a plan that one presents to potential investors in a product, project or business. 

Day 2 is split into two parts – 
- Part 1, create pitches 
- Part 2, critique of pitches 

In part 1 you will prepare a pitch based on ideas for an AI-based product that helps stop a species from becoming extinct. 

In part 2, your tutors and mentors will play the role of investors. Your task is to persuade these investors to fund your product’s development. 

There will be 1 winner, and the criteria that the investors will be using is as follows: 

1.	Realistic impact on a big, clearly-defined problem, 20% 
2.	Description of how machine learning will be used, especially with regards to the data and models, 30% 
3.	Demo of the key principles in Excel or Python, 20% 
4.	Clarity of communication, 10%
5.	Time keeping – minus 10% for each 15 seconds over the pitch time 
6.	During the critique of the other team’s pitches, your team can earn 2.5% points up to a maximum of 10% for each good question that you put to another team during the critique. 

#### Preparation 
You will need to produce a PowerPoint for the pitch. Try to use diagrams rather than words on the slides. Your slides should follow the AI development process that we studied at the start of this hackathon, with one slide explaining each step in the process.  

You will need the following 7 slides - 

Define Problem > Hypothesise > Prepare Data > Model Data > Deploy

- Title slide - stating the name of your team and your idea 
- Problem definition  – in one short sentence, what problem will your product solve? 
- Your hypothesis, which should explain how you think AI can help solve the problem 
- You will need a slide explaining what data you need , where you will get it from and how you will prepare it for machine learning 
- In a ‘modelling’ slide, you will need to explain which machine learning model is the best fit to solve the problem 
- You will need two ‘deploy’ slides - 
    - The first needs to show the Technical components as ‘building blocks’ 
    - The second needs to show designs for how your model will work with data. If you can share your screen and give a short demonstration, even better.  

You will need to load your presentation into your teams area in Teams before the start of the critique. 

#### Delivery 

You will have 5 minutes only to present, and then there will be 5 mins Q&A. 

#### Critique 

Whilst other teams are presenting, it will be tempting for you to disengage from the critique. However, you can earn extra points for your team if you pay attention to the other pitches and contribute questions. 

### Design A Web Service That Protects An Endangered Species		

Design and build a pitch for an AI-based service that protects an endangered species. 	

### Present, And Participate In The Critique  
Don’t forget that during the critique of the other team’s pitches, your team can earn 5% points up to a maximum of 20% for each good question that you put to another team during the critique.

Figure 138. Your team can earn extra points if you participate fully in the critique

### References
https://hai.stanford.edu/sites/default/files/ai_index_2019_report.pdf
https://earthobservatory.nasa.gov/features/EnergyBalance
https://www.acs.org/content/acs/en/climatescience/atmosphericwarming/singlelayermodel.html
https://climate.ncsu.edu/edu/Albedo
Schneider, S. H. & Dickinson, R. E. Climate modelling. Rev. Geophys. 12, 447–493 (1974), cited in Nature - https://www.nature.com/articles/s41598-017-08467-z 
https://www.space.com/17816-earth-temperature.html 
https://www.un.org/sustainabledevelopment/blog/2019/05/nature-decline-unprecedented-report/
https://earthobservatory.nasa.gov/world-of-change/Biosphere
https://climate.nasa.gov/evidence/
https://publications.iom.int/books/mrs-ndeg31-migration-and-climate-change
https://blogs.microsoft.com/blog/2020/01/16/microsoft-will-be-carbon-negative-by-2030/
https://blogs.microsoft.com/blog/2020/09/21/microsoft-will-replenish-more-water-than-it-consumes-by-2030/
https://blogs.microsoft.com/blog/2020/08/04/microsoft-direct-operations-products-and-packaging-to-be-zero-waste-by-2030/
https://www.microsoft.com/en-us/ai/ai-for-good
https://www.silviaterra.com
https://news.ubc.ca/2016/01/19/study-finds-30-per-cent-of-global-fish-catch-is-unreported/
https://www.nature.com/articles/ncomms10244
https://www.bbc.com/future/article/20120920-are-we-running-out-of-fish
https://www.worldbank.org/en/topic/oceans-fisheries-and-coastal-economies
https://www.oceanmind.global
https://www.oceanmind.global/microsoft/
https://www.microsoft.com/en-us/ai/ai-for-earth-ag-analytics 
https://www.microsoft.com/en-us/ai/ai-for-earth-cloud-agronomics
https://phys.org/news/2020-06-football-pitch-rainforest-seconds.html 
